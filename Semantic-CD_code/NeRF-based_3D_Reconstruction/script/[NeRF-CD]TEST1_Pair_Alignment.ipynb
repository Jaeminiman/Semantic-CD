{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Image Pairing(Vocab tree-based retriever)\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "def match_index(filename, indices):\n",
    "        try:\n",
    "            base = os.path.splitext(filename)[0]\n",
    "            num_part = base.split(\"_\")[-1]  # 예: frame_00001 → 00001\n",
    "            return int(num_part) in indices\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % 2147483647\n",
    "    image_id1 = (pair_id - image_id2) / 2147483647\n",
    "    return image_id1, image_id2\n",
    "\n",
    "def extract_best_matches(database_path):\n",
    "    \"\"\"DB에서 가장 높은 similarity 쌍을 src1:src2 매칭으로 추출\"\"\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # image_id ↔ name 매핑\n",
    "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
    "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "\n",
    "    # matches 테이블에서 best match 추출\n",
    "    matches = defaultdict(list)\n",
    "    cursor.execute(\"SELECT pair_id, rows FROM two_view_geometries WHERE rows > 0\")\n",
    "    for pair_id, score in cursor.fetchall():\n",
    "        \n",
    "        image_id1, image_id2 = pair_id_to_image_ids(pair_id)\n",
    "        name1, name2 = id_to_name[image_id1], id_to_name[image_id2]\n",
    "        print(name1, name2)\n",
    "        if name1.startswith(\"frame_\") and name2.startswith(\"new_frame_\"):\n",
    "            \n",
    "            matches[name2].append((name1, score))\n",
    "        elif name2.startswith(\"frame_\") and name1.startswith(\"new_frame_\"):\n",
    "            print(1)\n",
    "            matches[name1].append((name2, score))        \n",
    "\n",
    "    # best match 추출\n",
    "    best_matches = {}    \n",
    "    for t2_name, pair_list in matches.items():\n",
    "        pair_list.sort(key=lambda x: -x[1])  # score 높은 순\n",
    "        t1_name = pair_list[0][0]\n",
    "        print(t1_name, t2_name, pair_list[0][1])\n",
    "        best_matches[t2_name] = t1_name\n",
    "\n",
    "    conn.close()\n",
    "    return best_matches\n",
    "\n",
    "def copy_best_pairs(src_folder_1, src_folder_2, dest_dir, best_match, indices):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    log_path = os.path.join(dest_dir, \"matched_pairs.txt\")\n",
    "\n",
    "    with open(log_path, \"w\") as log_file:\n",
    "        for t2_name, t1_name in best_match.items():\n",
    "            if not t2_name.startswith(\"new_\"):\n",
    "                raise ValueError(f\"❌ t2_name은 'new_'로 시작해야 합니다: {t2_name}\")\n",
    "            \n",
    "            if indices is not None and not match_index(t2_name, indices):\n",
    "                continue  # 인덱스에 포함되지 않으면 건너뜀\n",
    "\n",
    "            t1_dest = t2_name.replace(\"new_\", \"initial_paired_\", 1)\n",
    "            t2_dest = t2_name\n",
    "\n",
    "            shutil.copy(os.path.join(src_folder_1, t1_name), os.path.join(dest_dir, t1_dest))\n",
    "            shutil.copy(os.path.join(src_folder_2, t2_name), os.path.join(dest_dir, t2_dest))\n",
    "            log_file.write(f\"{t2_name}, {t1_name} → {t2_dest}, {t1_dest}\\n\")\n",
    "\n",
    "    print(f\"✅ 선택된 페어 복사 및 기록 완료 → {dest_dir}\")\n",
    "\n",
    "def run_vocab_tree_matching_pipeline(src1, src2, dest_dir, db_path, indices):\n",
    "    best_matches = extract_best_matches(db_path)\n",
    "    print(best_matches)\n",
    "    copy_best_pairs(src1, src2, dest_dir, best_matches, indices)\n",
    "\n",
    "# 사용 예시\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Naju_90m_ChangeDetection_workspace/trial5\"\n",
    "\n",
    "src_folder_1 = os.path.join(workspace_dir, \"initial/ns_processed/images\")\n",
    "src_folder_2 = os.path.join(workspace_dir, \"new_correspondence/ns_processed/images\")\n",
    "database_path = os.path.join(workspace_dir, \"new_correspondence/ns_processed/colmap/database.db\")\n",
    "indices_path = os.path.join(workspace_dir, \"new_correspondence/renders/image_indices.npy\")\n",
    "\n",
    "if os.path.exists(indices_path):\n",
    "    indices = np.load(indices_path)\n",
    "    dest_folder = os.path.join(workspace_dir, \"CD_PAIR/baseline_cd_pair\")\n",
    "    print(f\"Loaded {len(indices)} indices from {indices_path}\")\n",
    "else:\n",
    "    indices = None\n",
    "    dest_folder = os.path.join(workspace_dir, \"CD_PAIR/baseline_cd_pair\")\n",
    "    print(f\"No file found at {indices_path}, indices set to None.\")\n",
    "\n",
    "run_vocab_tree_matching_pipeline(src_folder_1, src_folder_2, dest_folder, database_path, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Image Pairing(RMSE-based retriever)\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "def match_index(filename, indices):\n",
    "        try:\n",
    "            base = os.path.splitext(filename)[0]\n",
    "            num_part = base.split(\"_\")[-1]  # 예: frame_00001 → 00001\n",
    "            return int(num_part) in indices\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % 2147483647\n",
    "    image_id1 = (pair_id - image_id2) / 2147483647\n",
    "    return image_id1, image_id2\n",
    "\n",
    "def load_keypoints(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT image_id, data FROM keypoints\")\n",
    "    kp_dict = {}\n",
    "    for image_id, kp_blob in cursor.fetchall():\n",
    "        keypoints = np.frombuffer(kp_blob, dtype=np.float32).reshape(-1, 6)[:, :2]\n",
    "        kp_dict[image_id] = keypoints\n",
    "    return kp_dict\n",
    "\n",
    "def extract_best_matches_by_rmse(database_path):\n",
    "    \"\"\"vocab tree 기반 매칭 결과에서 RMSE 기준으로 best match 추출\"\"\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # image_id ↔ name 매핑\n",
    "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
    "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "    name_to_id = {v: k for k, v in id_to_name.items()}\n",
    "\n",
    "    keypoints = load_keypoints(conn)\n",
    "\n",
    "    matches_by_new_img = defaultdict(list)\n",
    "\n",
    "    # matches 추출\n",
    "    cursor.execute(\"SELECT pair_id, data FROM matches WHERE data IS NOT NULL\")\n",
    "    match_data = {row[0]: np.frombuffer(row[1], dtype=np.uint32).reshape(-1, 2) for row in cursor.fetchall()}\n",
    "\n",
    "    # geometry (유효한 매칭만)\n",
    "    cursor.execute(\"SELECT pair_id, rows FROM two_view_geometries WHERE rows > 0\")\n",
    "    for pair_id, num_matches in cursor.fetchall():\n",
    "        image_id1, image_id2 = pair_id_to_image_ids(pair_id)\n",
    "        if image_id1 not in keypoints or image_id2 not in keypoints:\n",
    "            continue\n",
    "        name1, name2 = id_to_name[image_id1], id_to_name[image_id2]\n",
    "\n",
    "        # 매칭 이름 조건 필터\n",
    "        if name1.startswith(\"frame_\") and name2.startswith(\"new_frame_\"):\n",
    "            t1_id, t2_id = image_id1, image_id2\n",
    "            t1_name, t2_name = name1, name2\n",
    "        elif name2.startswith(\"frame_\") and name1.startswith(\"new_frame_\"):\n",
    "            t1_id, t2_id = image_id2, image_id1\n",
    "            t1_name, t2_name = name2, name1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # 매칭 점 추출\n",
    "        matches = match_data.get(pair_id)\n",
    "        if matches is None or len(matches) == 0:\n",
    "            continue\n",
    "\n",
    "        kp1 = keypoints[t1_id][matches[:, 0]]\n",
    "        kp2 = keypoints[t2_id][matches[:, 1]]\n",
    "\n",
    "        rmse = np.sqrt(np.mean(np.sum((kp1 - kp2) ** 2, axis=1)))\n",
    "        matches_by_new_img[t2_name].append((t1_name, rmse, len(matches)))\n",
    "\n",
    "    # best match는 RMSE 기준으로 선정\n",
    "    best_match = {}\n",
    "    for t2_name, candidates in matches_by_new_img.items():\n",
    "        candidates.sort(key=lambda x: x[1])  # RMSE 오름차순\n",
    "        best = candidates[0]\n",
    "        print(f\"[{t2_name}] ← {best[0]} | RMSE: {best[1]:.2f}, matches: {best[2]}\")\n",
    "        best_match[t2_name] = best[0]\n",
    "\n",
    "    conn.close()\n",
    "    return best_match\n",
    "\n",
    "def extract_top_k_matches(database_path, top_k=5):\n",
    "    \"\"\"DB에서 상위 k개의 vocab 유사도 후보 추출\"\"\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
    "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "\n",
    "    matches = defaultdict(list)\n",
    "    cursor.execute(\"SELECT pair_id, rows FROM two_view_geometries WHERE rows > 0\")\n",
    "    for pair_id, score in cursor.fetchall():\n",
    "        image_id1, image_id2 = pair_id_to_image_ids(pair_id)\n",
    "        name1, name2 = id_to_name[image_id1], id_to_name[image_id2]\n",
    "        if name1.startswith(\"frame_\") and name2.startswith(\"new_frame_\"):\n",
    "            matches[name2].append((name1, score))\n",
    "        elif name2.startswith(\"frame_\") and name1.startswith(\"new_frame_\"):\n",
    "            matches[name1].append((name2, score))\n",
    "\n",
    "    top_matches = {}\n",
    "    for new_name, pair_list in matches.items():\n",
    "        pair_list.sort(key=lambda x: -x[1])\n",
    "        top_matches[new_name] = pair_list[:top_k]\n",
    "\n",
    "    conn.close()\n",
    "    return top_matches\n",
    "\n",
    "\n",
    "def copy_best_pairs(src_folder_1, src_folder_2, dest_dir, best_match, indices):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    log_path = os.path.join(dest_dir, \"matched_pairs.txt\")\n",
    "\n",
    "    with open(log_path, \"w\") as log_file:\n",
    "        for t2_name, t1_name in best_match.items():\n",
    "            if not t2_name.startswith(\"new_\"):\n",
    "                raise ValueError(f\"❌ t2_name은 'new_'로 시작해야 합니다: {t2_name}\")\n",
    "\n",
    "            if indices is not None and not match_index(t2_name, indices):\n",
    "                continue  # 인덱스에 포함되지 않으면 건너뜀\n",
    "\n",
    "            t1_dest = t2_name.replace(\"new_\", \"initial_paired_\", 1)\n",
    "            t2_dest = t2_name\n",
    "\n",
    "            shutil.copy(os.path.join(src_folder_1, t1_name), os.path.join(dest_dir, t1_dest))\n",
    "            shutil.copy(os.path.join(src_folder_2, t2_name), os.path.join(dest_dir, t2_dest))\n",
    "            log_file.write(f\"{t2_name}, {t1_name} → {t2_dest}, {t1_dest}\\n\")\n",
    "\n",
    "    print(f\"✅ 선택된 페어 복사 및 기록 완료 → {dest_dir}\")\n",
    "\n",
    "def run_rmse_based_matching_pipeline(src1, src2, dest_dir, db_path, indices):\n",
    "    best_match = extract_best_matches_by_rmse(db_path)\n",
    "    copy_best_pairs(src1, src2, dest_dir, best_match, indices)\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Naju_90m_ChangeDetection_workspace/trial5\"\n",
    "src_folder_1 = os.path.join(workspace_dir, \"initial/ns_processed/images\")\n",
    "src_folder_2 = os.path.join(workspace_dir, \"new_correspondence/ns_processed/images\")\n",
    "database_path = os.path.join(workspace_dir, \"new_correspondence/ns_processed/colmap/database.db\")\n",
    "indices_path = os.path.join(workspace_dir, \"new_correspondence/renders/image_indices.npy\")\n",
    "\n",
    "if os.path.exists(indices_path):\n",
    "    indices = np.load(indices_path)\n",
    "    dest_folder = os.path.join(workspace_dir, \"CD_PAIR/baseline_cd_pair2\")\n",
    "    print(f\"Loaded {len(indices)} indices from {indices_path}\")\n",
    "else:\n",
    "    indices = None\n",
    "    dest_folder = os.path.join(workspace_dir, \"CD_PAIR/baseline_cd_pair2\")\n",
    "    print(f\"No file found at {indices_path}, indices set to None.\")\n",
    "\n",
    "run_rmse_based_matching_pipeline(src_folder_1, src_folder_2, dest_folder, database_path, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cece013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeRF image pair generation \n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def match_index(filename, indices):\n",
    "        try:\n",
    "            base = os.path.splitext(filename)[0]\n",
    "            num_part = base.split(\"_\")[-1]  # 예: frame_00001 → 00001\n",
    "            return int(num_part) in indices\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "def collect_jpg_pairs(src_dir1, src_dir2, dest_dir, indices, prefix = \"\"):\n",
    "    \"\"\"\n",
    "    첫번째 폴더에서는 'new_' prefix를 가진 jpg 파일만,\n",
    "    두번째 폴더에서는 모든 jpg 파일을 모아서\n",
    "    하나의 pair 폴더에 저장한다.\n",
    "\n",
    "    indices가 None이 아니면, 해당 인덱스에 해당하는 파일만 저장한다.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # 첫 번째 경로: new_ prefix jpg\n",
    "    jpg_files1 = [f for f in os.listdir(src_dir1) if f.startswith(prefix) and f.endswith(\".jpg\")]\n",
    "\n",
    "    # 두 번째 경로: 모든 jpg\n",
    "    jpg_files2 = [f for f in os.listdir(src_dir2) if f.endswith(\".jpg\")]\n",
    "\n",
    "    # 인덱스 필터링 적용\n",
    "    if indices is not None:\n",
    "        jpg_files1 = [f for f in jpg_files1 if match_index(f, indices)]\n",
    "        jpg_files2 = [f for f in jpg_files2 if match_index(f, indices)]\n",
    "    \n",
    "    # for f in jpg_files1:\n",
    "        # src_path = os.path.join(src_dir1, f)\n",
    "\n",
    "        # # 숫자 추출 및 1 증가\n",
    "        # name, ext = os.path.splitext(f)\n",
    "        # prefix, frame, number = name.split(\"_\")\n",
    "        # new_number = int(number)\n",
    "        # new_filename = f\"{prefix}_{frame}_{new_number:05d}{ext}\"  # zero-padding 5자리 유지\n",
    "\n",
    "        # dst_path = os.path.join(dest_dir, new_filename)\n",
    "        # shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    # 복사: src_dir1 (new_ prefix)\n",
    "    for f in jpg_files1:\n",
    "        src_path = os.path.join(src_dir1, f)\n",
    "        dst_path = os.path.join(dest_dir, f)\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    # 복사: src_dir2 (initial_paired_ prefix 추가)\n",
    "    for f in jpg_files2:\n",
    "        src_path = os.path.join(src_dir2, f)\n",
    "        dst_path = os.path.join(dest_dir, f\"initial_paired_{f}\")\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    print(f\"✅ 저장 완료: {len(jpg_files1)}개(new_) + {len(jpg_files2)}개(initial_) → {dest_dir}\")\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Sintanjin_80m_CD_workspace/longlong_trial1\"\n",
    "src_folder1 = os.path.join(workspace_dir, \"new_correspondence/ns_processed/new_images_2\")\n",
    "src_folder2 = os.path.join(workspace_dir, \"new_correspondence/renders\")\n",
    "\n",
    "indices_path = os.path.join(workspace_dir, \"new_correspondence/renders/image_indices.npy\")\n",
    "\n",
    "if os.path.exists(indices_path):\n",
    "    indices = np.load(indices_path)\n",
    "    dest_dir = os.path.join(workspace_dir, \"CD_PAIR/nerf_cd_pair\")\n",
    "    print(f\"Loaded {len(indices)} indices from {indices_path}\")\n",
    "else:\n",
    "    indices = None\n",
    "    dest_dir = os.path.join(workspace_dir, \"CD_PAIR/nerf_cd_pair\")\n",
    "    print(f\"No file found at {indices_path}, indices set to None.\")\n",
    "\n",
    "prefix = \"new_\" # if correspondence search, new_\n",
    "collect_jpg_pairs(src_folder1, src_folder2, dest_dir, indices, prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT-based RMSE Calculator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def draw_feature_matches(img1, kp1, img2, kp2, matches, max_display=50, save_path=None):\n",
    "    \"\"\"\n",
    "    이미지 1과 이미지 2의 feature 매칭 결과를 시각화 (최대 max_display개)\n",
    "    \"\"\"\n",
    "    img_matches = cv2.drawMatches(\n",
    "        img1, kp1,\n",
    "        img2, kp2,\n",
    "        matches[:max_display],\n",
    "        None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "    )\n",
    "\n",
    "    # BGR → RGB\n",
    "    img_matches = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(f\"Feature Matching (top {min(len(matches), max_display)} matches)\")\n",
    "    plt.imshow(img_matches)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def rotation_error_deg(R_est):\n",
    "    \"\"\"\n",
    "    Rotation matrix 간의 오차 (deg)\n",
    "    \"\"\"\n",
    "    R_gt = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    R_diff = R_est @ R_gt.T\n",
    "    trace_val = np.clip((np.trace(R_diff) - 1) / 2.0, -1.0, 1.0)  # clip for numerical safety\n",
    "    angle_rad = np.arccos(trace_val)\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def translation_direction_error_deg(t_est):\n",
    "    \"\"\"\n",
    "    방향 벡터 간의 오차 (deg)\n",
    "    (길이는 정규화되어 있어야 함)\n",
    "    \"\"\"\n",
    "    t_gt = np.array([[0], [0], [1]])\n",
    "    \n",
    "    t_gt = t_gt.flatten() / np.linalg.norm(t_gt)\n",
    "    t_est = t_est.flatten() / np.linalg.norm(t_est)\n",
    "    dot_val = np.clip(np.dot(t_gt, t_est), -1.0, 1.0)\n",
    "    angle_rad = np.arccos(dot_val)\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "\n",
    "\n",
    "def resize_image(img, resize_factor=None, max_size=None):\n",
    "    \"\"\"\n",
    "    이미지 다운스케일 함수\n",
    "    - resize_factor 주어지면 해당 배수로 축소\n",
    "    - max_size가 주어지면 해당 최대 크기 기준으로 축소\n",
    "    둘 중 하나만 사용하세요.\n",
    "    \n",
    "    반환: (resized_img, scale)\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if resize_factor is not None:\n",
    "        scale = 1.0 / resize_factor\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        return resized_img, scale\n",
    "\n",
    "    elif max_size is not None:\n",
    "        scale = min(max_size / h, max_size / w)\n",
    "        if scale < 1.0:\n",
    "            new_w = int(w * scale)\n",
    "            new_h = int(h * scale)\n",
    "            resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            resized_img = img\n",
    "            scale = 1.0\n",
    "        return resized_img, scale\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either downscale_factor or max_size must be provided.\")\n",
    "\n",
    "\n",
    "def evaluate_pose_match(src_dir, transforms_path, altitude_m, downscale_factor = 1, resize_factor = 1, sensor_pixel_size_mm = None, prefix=\"\"):\n",
    "    image_pairs = []\n",
    "    for img1_path in sorted(glob(os.path.join(src_dir, \"initial_paired_frame_*.jpg\"))):\n",
    "        basename = os.path.basename(img1_path).replace(\"initial_paired_\", \"\")\n",
    "        img2_path = os.path.join(src_dir, f\"{prefix}{basename}\")\n",
    "        if os.path.exists(img2_path):\n",
    "            image_pairs.append((img1_path, img2_path))\n",
    "\n",
    "    rmses_pixel = []\n",
    "    rmses_meter = []\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # 카메라 파라미터 로드\n",
    "    K, dist_coeffs = load_camera_intrinsics(transforms_path)\n",
    "\n",
    "    gsd_m_per_pixel = calculate_gsd(altitude_m, K, downscale_factor)\n",
    "    \n",
    "\n",
    "    for idx, (img1_path, img2_path) in enumerate(image_pairs):\n",
    "        \n",
    "        img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        print(f\"original: {img1.shape}\")\n",
    "        img1, scale1 = resize_image(img1, resize_factor=resize_factor)\n",
    "        img2, scale2 = resize_image(img2, resize_factor=resize_factor)\n",
    "        print(f\"reshaped: {img1.shape}\")    \n",
    "        assert scale1 == scale2\n",
    "        scale = scale1\n",
    "        \n",
    "        kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "        if des1 is None or des2 is None:\n",
    "            print(f\"❌ No features in {img1_path}\")\n",
    "            continue\n",
    "\n",
    "        matcher = cv2.BFMatcher()\n",
    "        matches = matcher.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Ratio test\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.8 * n.distance:\n",
    "                good_matches.append(m)\n",
    "                \n",
    "        # good_matches = bidirectional_match(des1, des2, matcher, ratio_thresh=1.0)\n",
    "\n",
    "        if len(good_matches) < 8:\n",
    "            print(f\"❌ Not enough good matches: {len(good_matches)}\")\n",
    "            continue\n",
    "\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "        \n",
    "\n",
    "        # Guided Matching: RANSAC 기반 Fundamental Matrix 추정으로 inlier 필터링\n",
    "        F, inliers = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, ransacReprojThreshold=3.0, confidence=0.99)\n",
    "\n",
    "\n",
    "        inliers = inliers.ravel().astype(bool)\n",
    "        inlier_pts1 = pts1[inliers]\n",
    "        inlier_pts2 = pts2[inliers]\n",
    "        inlier_matches = [m for m, inlier in zip(good_matches, inliers) if inlier]\n",
    "\n",
    "        if idx == len(image_pairs) -1 :\n",
    "            draw_feature_matches(img1, kp1, img2, kp2, inlier_matches)\n",
    "                \n",
    "        # RMSE 계산\n",
    "        meter_dists = np.linalg.norm(inlier_pts1 - inlier_pts2, axis=1) * gsd_m_per_pixel / scale\n",
    "        valid_idx = meter_dists < 30.0\n",
    "\n",
    "        if np.sum(valid_idx) == 0:\n",
    "            print(\"⚠️ No inliers under 30m threshold.\")\n",
    "            continue\n",
    "\n",
    "        filtered_pts1 = inlier_pts1[valid_idx]\n",
    "        filtered_pts2 = inlier_pts2[valid_idx]\n",
    "\n",
    "        filtered_rmse_pixel = np.sqrt(np.mean(np.sum((filtered_pts1 - filtered_pts2)**2, axis=1)))\n",
    "        filtered_rmse_meter = filtered_rmse_pixel * gsd_m_per_pixel / scale\n",
    "\n",
    "        print(f\"✅ RMSE (inliers < 30m): {filtered_rmse_pixel:.4f} px | {filtered_rmse_meter:.4f} m (Count: {np.sum(valid_idx)})\")\n",
    "\n",
    "        rmses_pixel.append(filtered_rmse_pixel)\n",
    "        rmses_meter.append(filtered_rmse_meter)\n",
    "            \n",
    "        \n",
    "    mean_rmse_pixel = np.array(rmses_pixel).mean()\n",
    "    mean_rmse_meter = np.array(rmses_meter).mean()\n",
    "\n",
    "    print(f\"✅ Mean RMSE: {mean_rmse_pixel:.4f} px | {mean_rmse_meter:.4f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c497348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inliers after RANSAC for initial_paired_frame_00045.jpg: 363\n",
      "✅ Saved aligned: initial_paired_frame_00045.jpg\n",
      "✅ Saved homography: frame_00045.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00047.jpg: 371\n",
      "✅ Saved aligned: initial_paired_frame_00047.jpg\n",
      "✅ Saved homography: frame_00047.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00049.jpg: 252\n",
      "✅ Saved aligned: initial_paired_frame_00049.jpg\n",
      "✅ Saved homography: frame_00049.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00051.jpg: 273\n",
      "✅ Saved aligned: initial_paired_frame_00051.jpg\n",
      "✅ Saved homography: frame_00051.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00053.jpg: 205\n",
      "✅ Saved aligned: initial_paired_frame_00053.jpg\n",
      "✅ Saved homography: frame_00053.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00055.jpg: 170\n",
      "✅ Saved aligned: initial_paired_frame_00055.jpg\n",
      "✅ Saved homography: frame_00055.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00057.jpg: 214\n",
      "✅ Saved aligned: initial_paired_frame_00057.jpg\n",
      "✅ Saved homography: frame_00057.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00059.jpg: 195\n",
      "✅ Saved aligned: initial_paired_frame_00059.jpg\n",
      "✅ Saved homography: frame_00059.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00061.jpg: 72\n",
      "✅ Saved aligned: initial_paired_frame_00061.jpg\n",
      "✅ Saved homography: frame_00061.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00063.jpg: 64\n",
      "✅ Saved aligned: initial_paired_frame_00063.jpg\n",
      "✅ Saved homography: frame_00063.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00065.jpg: 135\n",
      "✅ Saved aligned: initial_paired_frame_00065.jpg\n",
      "✅ Saved homography: frame_00065.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00067.jpg: 295\n",
      "✅ Saved aligned: initial_paired_frame_00067.jpg\n",
      "✅ Saved homography: frame_00067.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00069.jpg: 234\n",
      "✅ Saved aligned: initial_paired_frame_00069.jpg\n",
      "✅ Saved homography: frame_00069.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00071.jpg: 293\n",
      "✅ Saved aligned: initial_paired_frame_00071.jpg\n",
      "✅ Saved homography: frame_00071.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00073.jpg: 324\n",
      "✅ Saved aligned: initial_paired_frame_00073.jpg\n",
      "✅ Saved homography: frame_00073.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00075.jpg: 434\n",
      "✅ Saved aligned: initial_paired_frame_00075.jpg\n",
      "✅ Saved homography: frame_00075.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00077.jpg: 436\n",
      "✅ Saved aligned: initial_paired_frame_00077.jpg\n",
      "✅ Saved homography: frame_00077.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00079.jpg: 567\n",
      "✅ Saved aligned: initial_paired_frame_00079.jpg\n",
      "✅ Saved homography: frame_00079.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00081.jpg: 400\n",
      "✅ Saved aligned: initial_paired_frame_00081.jpg\n",
      "✅ Saved homography: frame_00081.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00083.jpg: 233\n",
      "✅ Saved aligned: initial_paired_frame_00083.jpg\n",
      "✅ Saved homography: frame_00083.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00085.jpg: 107\n",
      "✅ Saved aligned: initial_paired_frame_00085.jpg\n",
      "✅ Saved homography: frame_00085.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00087.jpg: 323\n",
      "✅ Saved aligned: initial_paired_frame_00087.jpg\n",
      "✅ Saved homography: frame_00087.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00089.jpg: 226\n",
      "✅ Saved aligned: initial_paired_frame_00089.jpg\n",
      "✅ Saved homography: frame_00089.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00091.jpg: 43\n",
      "✅ Saved aligned: initial_paired_frame_00091.jpg\n",
      "✅ Saved homography: frame_00091.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00093.jpg: 192\n",
      "✅ Saved aligned: initial_paired_frame_00093.jpg\n",
      "✅ Saved homography: frame_00093.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00095.jpg: 156\n",
      "✅ Saved aligned: initial_paired_frame_00095.jpg\n",
      "✅ Saved homography: frame_00095.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00097.jpg: 195\n",
      "✅ Saved aligned: initial_paired_frame_00097.jpg\n",
      "✅ Saved homography: frame_00097.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00099.jpg: 185\n",
      "✅ Saved aligned: initial_paired_frame_00099.jpg\n",
      "✅ Saved homography: frame_00099.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00101.jpg: 178\n",
      "✅ Saved aligned: initial_paired_frame_00101.jpg\n",
      "✅ Saved homography: frame_00101.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00103.jpg: 166\n",
      "✅ Saved aligned: initial_paired_frame_00103.jpg\n",
      "✅ Saved homography: frame_00103.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00105.jpg: 182\n",
      "✅ Saved aligned: initial_paired_frame_00105.jpg\n",
      "✅ Saved homography: frame_00105.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00107.jpg: 198\n",
      "✅ Saved aligned: initial_paired_frame_00107.jpg\n",
      "✅ Saved homography: frame_00107.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00109.jpg: 330\n",
      "✅ Saved aligned: initial_paired_frame_00109.jpg\n",
      "✅ Saved homography: frame_00109.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00111.jpg: 191\n",
      "✅ Saved aligned: initial_paired_frame_00111.jpg\n",
      "✅ Saved homography: frame_00111.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00121.jpg: 85\n",
      "✅ Saved aligned: initial_paired_frame_00121.jpg\n",
      "✅ Saved homography: frame_00121.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00123.jpg: 70\n",
      "✅ Saved aligned: initial_paired_frame_00123.jpg\n",
      "✅ Saved homography: frame_00123.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00125.jpg: 105\n",
      "✅ Saved aligned: initial_paired_frame_00125.jpg\n",
      "✅ Saved homography: frame_00125.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00127.jpg: 122\n",
      "✅ Saved aligned: initial_paired_frame_00127.jpg\n",
      "✅ Saved homography: frame_00127.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00129.jpg: 66\n",
      "✅ Saved aligned: initial_paired_frame_00129.jpg\n",
      "✅ Saved homography: frame_00129.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00131.jpg: 89\n",
      "✅ Saved aligned: initial_paired_frame_00131.jpg\n",
      "✅ Saved homography: frame_00131.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00133.jpg: 117\n",
      "✅ Saved aligned: initial_paired_frame_00133.jpg\n",
      "✅ Saved homography: frame_00133.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00135.jpg: 83\n",
      "✅ Saved aligned: initial_paired_frame_00135.jpg\n",
      "✅ Saved homography: frame_00135.npy\n",
      "✅ Inliers after RANSAC for initial_paired_frame_00137.jpg: 169\n",
      "✅ Saved aligned: initial_paired_frame_00137.jpg\n",
      "✅ Saved homography: frame_00137.npy\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def resize_image(img, resize_factor=None, max_size=None):\n",
    "    \"\"\"\n",
    "    이미지 다운스케일 함수\n",
    "    - resize_factor 주어지면 해당 배수로 축소\n",
    "    - max_size가 주어지면 해당 최대 크기 기준으로 축소\n",
    "    둘 중 하나만 사용하세요.\n",
    "    \n",
    "    반환: (resized_img, scale)\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if resize_factor is not None:\n",
    "        scale = 1.0 / resize_factor\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        return resized_img, scale\n",
    "\n",
    "    elif max_size is not None:\n",
    "        scale = min(max_size / h, max_size / w)\n",
    "        if scale < 1.0:\n",
    "            new_w = int(w * scale)\n",
    "            new_h = int(h * scale)\n",
    "            resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            resized_img = img\n",
    "            scale = 1.0\n",
    "        return resized_img, scale\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either downscale_factor or max_size must be provided.\")\n",
    "\n",
    "def warp_img1_to_img2_and_save(src_dir, output_dir, resize_factor, prefix=\"\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    homography_dir = os.path.join(output_dir, \"homography\")\n",
    "    os.makedirs(homography_dir, exist_ok=True)\n",
    "\n",
    "    image_pairs = []\n",
    "    for img1_path in sorted(glob(os.path.join(src_dir, \"initial_paired_frame_*.jpg\"))):\n",
    "        basename = os.path.basename(img1_path).replace(\"initial_paired_\", \"\")\n",
    "        img2_path = os.path.join(src_dir, f\"{prefix}{basename}\")\n",
    "        if os.path.exists(img2_path):\n",
    "            image_pairs.append((img1_path, img2_path))\n",
    "    \n",
    "    for idx, (img1_path, img2_path) in enumerate(image_pairs):\n",
    "        \n",
    "        sift = cv2.SIFT_create()\n",
    "\n",
    "        img1_rgb = cv2.imread(img1_path)\n",
    "        img2_rgb = cv2.imread(img2_path)\n",
    "\n",
    "\n",
    "        image1 = img1_rgb.copy()\n",
    "        image2 = img2_rgb.copy()\n",
    "\n",
    "        img1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "        img2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img1_resize, scale1 = resize_image(img1, resize_factor)\n",
    "        img2_resize, scale2 = resize_image(img2, resize_factor)\n",
    "\n",
    "        kp1, des1 = sift.detectAndCompute(img1_resize, None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2_resize, None)\n",
    "\n",
    "\n",
    "        if des1 is None or des2 is None:\n",
    "            print(f\"❌ No features in {img1_path}\")\n",
    "            continue\n",
    "\n",
    "        matcher = cv2.BFMatcher()\n",
    "        matches = matcher.knnMatch(des1, des2, k=2)\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "\n",
    "        if len(good_matches) < 10:\n",
    "            print(f\"❌ Not enough good matches: {len(good_matches)}\")\n",
    "            continue\n",
    "\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "        F, inliers = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, ransacReprojThreshold=3.0, confidence=0.99)\n",
    "        if inliers is None or inliers.sum() < 10:\n",
    "            print(f\"❌ Fundamental matrix failed or insufficient inliers.\")\n",
    "            continue\n",
    "\n",
    "        pts1 = pts1[inliers.ravel() == 1]\n",
    "        pts2 = pts2[inliers.ravel() == 1]\n",
    "\n",
    "        H, inliers = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "        if H is None or inliers is None or inliers.sum() < 10:\n",
    "            print(f\"❌ Homography too unstable or insufficient inliers: {inliers.sum()}\")\n",
    "            continue\n",
    "\n",
    "        scale_matrix = np.eye(3)\n",
    "        scale_matrix[0, 0] = 1 / scale1\n",
    "        scale_matrix[1, 1] = 1 / scale1\n",
    "        H_scaled = scale_matrix @ H @ np.linalg.inv(scale_matrix)\n",
    "\n",
    "        print(f\"✅ Inliers after RANSAC for {os.path.basename(img1_path)}: {inliers.sum()}\")\n",
    "\n",
    "        height, width = img2.shape\n",
    "        corrected_image1 = cv2.warpPerspective(img1_rgb, H_scaled, (width, height))\n",
    "\n",
    "        mask_warped = np.zeros_like(img1_rgb, dtype=np.uint8)\n",
    "        cv2.warpPerspective(np.ones_like(img1_rgb, dtype=np.uint8), H_scaled, (width, height), dst=mask_warped, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "        corrected_image2 = img2_rgb * mask_warped\n",
    "\n",
    "        base_img2_path = os.path.basename(img2_path)\n",
    "        warped_img1_path = os.path.basename(img1_path)\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_dir, base_img2_path), corrected_image2)\n",
    "        cv2.imwrite(os.path.join(output_dir, warped_img1_path), corrected_image1)\n",
    "\n",
    "        # Save Homography matrix\n",
    "        \n",
    "        homography_name = os.path.splitext(base_img2_path)[0]  + \".npy\"\n",
    "        homography_name = homography_name[len(prefix):]  # prefix 제거\n",
    "        np.save(os.path.join(homography_dir, homography_name), H_scaled)\n",
    "\n",
    "        print(f\"✅ Saved aligned: {warped_img1_path}\")\n",
    "        print(f\"✅ Saved homography: {homography_name}\")\n",
    "\n",
    "# Example usage\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Sintanjin_80m_CD_workspace/longlong_trial1\"\n",
    "# src_dir = os.path.join(workspace_dir, \"CD_PAIR/nerf_cd_pair\")\n",
    "# output_dir = os.path.join(workspace_dir, \"CD_PAIR/nerf_cd_pair_rectified\")\n",
    "src_dir = os.path.join(workspace_dir, \"CD_PAIR/baseline_cd_pair\")\n",
    "output_dir = os.path.join(workspace_dir, \"CD_PAIR/baseline_cd_pair_rectified\")\n",
    "warp_img1_to_img2_and_save(src_dir, output_dir, resize_factor=4, prefix=\"new_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d97d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculator base functions\n",
    "\n",
    "def calculate_gsd(altitude_m, K, sensor_pixel_size_mm = None):\n",
    "    fx = K[0, 0] # focal length in pixel (x axis)    \n",
    "    # sensor_pixel_size_m = sensor_pixel_size_mm / 1000.0  # mm → meter\n",
    "\n",
    "    # GSD 계산\n",
    "    # gsd_m_per_pixel = (altitude_m * sensor_pixel_size_m) / (fx * sensor_pixel_size_m)\n",
    "    gsd_m_per_pixel = altitude_m / fx  # 결국 pixel size가 상쇄됨\n",
    "\n",
    "    print(f\"📏 GSD (m/pixel): {gsd_m_per_pixel:.6f}\")\n",
    "    return gsd_m_per_pixel\n",
    "\n",
    "def load_camera_intrinsics(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    fx = data['fl_x']\n",
    "    fy = data['fl_y']\n",
    "    cx = data['cx']\n",
    "    cy = data['cy']\n",
    "    K = np.array([\n",
    "        [fx,  0, cx],\n",
    "        [ 0, fy, cy],\n",
    "        [ 0,  0,  1]\n",
    "    ])\n",
    "    dist_coeffs = np.array([\n",
    "        data.get('k1', 0.0),\n",
    "        data.get('k2', 0.0),\n",
    "        data.get('p1', 0.0),\n",
    "        data.get('p2', 0.0),\n",
    "        0  # optional k3 if needed\n",
    "    ])\n",
    "\n",
    "    w = data['w']\n",
    "    h = data['h']\n",
    "\n",
    "    return K, dist_coeffs, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ff69fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click-based RMSE Calculator\n",
    "import json\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "def load_features(json_path, prefix_to_strip=\"\", downscale = 1):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    features = {}\n",
    "    for item in data:\n",
    "        filename = item['filename']\n",
    "        if prefix_to_strip and filename.startswith(prefix_to_strip):\n",
    "            filename = filename[len(prefix_to_strip):]  # prefix 제거\n",
    "        features[filename] = np.array(item['keypoints'], dtype=np.float32) * downscale\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "def compute_rmse(points_a, points_b):\n",
    "    if len(points_a) != 5 or len(points_b) != 5:\n",
    "        print(\"error occured. length of points is not 5!\")\n",
    "        return None, 0    \n",
    "\n",
    "    length = len(points_a)\n",
    "\n",
    "    # 유효 인덱스 (둘 다 [-1, -1]이 아닌 경우만)\n",
    "    valid_indices = [\n",
    "        i for i in range(length)\n",
    "        if (points_a[i][0] >= 0 or points_a[i][1] >= 0) and\n",
    "        (points_b[i][0] >= 0 or points_b[i][1] >= 0)\n",
    "    ]\n",
    "\n",
    "    if not valid_indices:\n",
    "        return None, 0  # 유효 포인트 없음\n",
    "\n",
    "    a_filtered = points_a[valid_indices]\n",
    "    b_filtered = points_b[valid_indices]\n",
    "\n",
    "    diff = a_filtered - b_filtered\n",
    "    rmse = np.sqrt(np.mean(np.sum(diff**2, axis=1)))\n",
    "    return rmse, len(valid_indices)\n",
    "\n",
    "def apply_homography_to_points(points_2d: np.ndarray, homography: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a homography transformation to 2D points.\n",
    "\n",
    "    Args:\n",
    "        points_2d (np.ndarray): Nx2 array of 2D points (x, y).\n",
    "        homography (np.ndarray): 3x3 homography matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Nx2 array of transformed 2D points.\n",
    "    \"\"\"\n",
    "    # Reshape to (N, 1, 2) for OpenCV\n",
    "    points_reshaped = points_2d.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Apply homography\n",
    "    transformed_points = cv2.perspectiveTransform(points_reshaped, homography)\n",
    "\n",
    "    # Reshape back to (N, 2)\n",
    "    return transformed_points.reshape(-1, 2)\n",
    "\n",
    "def compare_features(json_path_a, json_path_b, transforms_path, height_m, down_a=1, down_b=1, prefix_a = \"\", prefix_b = \"\", homography_dir = None):\n",
    "\n",
    "    # 카메라 파라미터 로드\n",
    "    K, dist_coeffs, width, height = load_camera_intrinsics(transforms_path)\n",
    "\n",
    "    gsd_m_per_pixel = calculate_gsd(height_m, K)\n",
    "\n",
    "    features_a = load_features(json_path_a, prefix_a, down_a)\n",
    "    features_b = load_features(json_path_b, prefix_b, down_b)\n",
    "\n",
    "    common_filenames = set(features_a.keys()) & set(features_b.keys())\n",
    "\n",
    "    \n",
    "    if not common_filenames:\n",
    "        print(\"No common filenames found.\")\n",
    "        return\n",
    "\n",
    "    rmse_list = []\n",
    "    rmse_pixel_list = []\n",
    "    used_pts_list = []\n",
    "    fail_count = 0\n",
    "    \n",
    "    total_used_pts = 0\n",
    "    total_possible_pts = 0\n",
    "\n",
    "    for filename in sorted(common_filenames):\n",
    "        raw_a = features_a[filename]\n",
    "        raw_b = features_b[filename]\n",
    "\n",
    "        if homography_dir is not None:\n",
    "            homography_path = os.path.join(homography_dir, f\"{os.path.splitext(filename)[0]}.npy\")\n",
    "            h_12_down = np.load(homography_path)\n",
    "\n",
    "            S = np.eye(3)\n",
    "            S[0, 0] = down_a\n",
    "            S[1, 1] = down_a\n",
    "\n",
    "            # H_orig = S_inv @ H @ S\n",
    "            S_inv = np.linalg.inv(S)            \n",
    "            h_12 = S @ h_12_down @ S_inv\n",
    "            raw_a = apply_homography_to_points(raw_a, h_12)\n",
    "            \n",
    "\n",
    "        rmse_pixel, used_pts = compute_rmse(raw_a, raw_b)        \n",
    "\n",
    "        possible_pts = min(len(raw_a), len(raw_b))\n",
    "        total_possible_pts += possible_pts\n",
    "        total_used_pts += used_pts\n",
    "\n",
    "        if rmse_pixel is None:\n",
    "            print(f\"{filename}: FAIL - no valid keypoints to compare\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "\n",
    "        rmse_meter = rmse_pixel * gsd_m_per_pixel\n",
    "        rmse_list.append((filename, rmse_meter)) \n",
    "        rmse_pixel_list.append((filename, rmse_pixel))        \n",
    "        used_pts_list.append((filename, used_pts))\n",
    "        print(f\"{filename}: RMSE = {rmse_meter:.2f}m, {rmse_pixel:.2f}pixel (used {used_pts}/{possible_pts} points)\")\n",
    "\n",
    "    if rmse_list:\n",
    "        sorted_rmse = sorted(rmse_list, key=lambda x: x[1])\n",
    "        sorted_used = sorted(used_pts_list, key=lambda x: x[1])\n",
    "\n",
    "        mean_rmse = np.mean([r[1] for r in rmse_list])\n",
    "        mean_rmse_pixel = np.mean([r[1] for r in rmse_pixel_list])\n",
    "        print(f\"\\n[✔] Average RMSE over {len(rmse_list)} images: {mean_rmse:.2f}m / {mean_rmse_pixel:.2f}pixels\")\n",
    "\n",
    "        print(\"\\n[🔺] Top 3 highest RMSE files:\")\n",
    "        for fname, val in sorted_rmse[-3:][::-1]:\n",
    "            print(f\"  {fname}: {val:.2f}m\")\n",
    "\n",
    "        print(\"\\n[🔻] Top 3 lowest RMSE files:\")\n",
    "        for fname, val in sorted_rmse[:3]:\n",
    "            print(f\"  {fname}: {val:.2f}m\")\n",
    "        \n",
    "        print(\"\\n[📉] Top 3 lowest used keypoints:\")\n",
    "        for fname, val in sorted_used[:3]:\n",
    "            print(f\"  {fname}: {val} points\")\n",
    "    else:\n",
    "        print(\"\\n[⚠] No valid images to compare.\")\n",
    "    \n",
    "    if total_possible_pts > 0:\n",
    "        used_ratio = total_used_pts / total_possible_pts\n",
    "        print(f\"\\n[ℹ] Average used keypoint ratio: {used_ratio:.2%} ({total_used_pts}/{total_possible_pts})\")\n",
    "\n",
    "    print(f\"\\n[!] Failed images due to invalid keypoints: {fail_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28121f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📏 GSD (m/pixel): 0.029846\n",
      "frame_00001.jpg: RMSE = 0.22m, 7.24pixel (used 5/5 points)\n",
      "frame_00004.jpg: RMSE = 0.26m, 8.70pixel (used 5/5 points)\n",
      "frame_00007.jpg: RMSE = 0.18m, 5.87pixel (used 5/5 points)\n",
      "frame_00010.jpg: RMSE = 0.21m, 7.13pixel (used 5/5 points)\n",
      "frame_00013.jpg: RMSE = 0.24m, 8.15pixel (used 5/5 points)\n",
      "frame_00016.jpg: RMSE = 0.22m, 7.27pixel (used 5/5 points)\n",
      "frame_00019.jpg: RMSE = 0.27m, 9.08pixel (used 5/5 points)\n",
      "frame_00022.jpg: RMSE = 0.24m, 8.12pixel (used 5/5 points)\n",
      "frame_00044.jpg: RMSE = 0.26m, 8.73pixel (used 5/5 points)\n",
      "frame_00047.jpg: RMSE = 0.36m, 12.00pixel (used 5/5 points)\n",
      "frame_00050.jpg: RMSE = 0.23m, 7.71pixel (used 5/5 points)\n",
      "frame_00053.jpg: RMSE = 0.20m, 6.53pixel (used 5/5 points)\n",
      "frame_00056.jpg: RMSE = 0.19m, 6.36pixel (used 5/5 points)\n",
      "frame_00059.jpg: RMSE = 0.14m, 4.80pixel (used 5/5 points)\n",
      "frame_00062.jpg: RMSE = 0.24m, 8.05pixel (used 5/5 points)\n",
      "frame_00065.jpg: RMSE = 0.26m, 8.83pixel (used 5/5 points)\n",
      "frame_00088.jpg: RMSE = 0.18m, 6.06pixel (used 5/5 points)\n",
      "frame_00091.jpg: RMSE = 0.20m, 6.84pixel (used 5/5 points)\n",
      "frame_00094.jpg: RMSE = 0.27m, 9.04pixel (used 5/5 points)\n",
      "frame_00097.jpg: RMSE = 0.16m, 5.50pixel (used 5/5 points)\n",
      "frame_00100.jpg: RMSE = 0.22m, 7.28pixel (used 5/5 points)\n",
      "frame_00103.jpg: RMSE = 0.16m, 5.48pixel (used 5/5 points)\n",
      "frame_00106.jpg: RMSE = 0.23m, 7.72pixel (used 5/5 points)\n",
      "frame_00109.jpg: RMSE = 0.24m, 7.92pixel (used 5/5 points)\n",
      "frame_00112.jpg: RMSE = 0.34m, 11.36pixel (used 5/5 points)\n",
      "frame_00115.jpg: RMSE = 0.19m, 6.46pixel (used 5/5 points)\n",
      "frame_00118.jpg: RMSE = 0.21m, 6.95pixel (used 5/5 points)\n",
      "frame_00133.jpg: RMSE = 0.15m, 5.02pixel (used 5/5 points)\n",
      "frame_00136.jpg: RMSE = 0.30m, 9.96pixel (used 5/5 points)\n",
      "frame_00139.jpg: RMSE = 0.27m, 9.02pixel (used 5/5 points)\n",
      "frame_00142.jpg: RMSE = 0.21m, 6.87pixel (used 5/5 points)\n",
      "frame_00145.jpg: RMSE = 0.18m, 5.87pixel (used 5/5 points)\n",
      "\n",
      "[✔] Average RMSE over 32 images: 0.23m / 7.56pixels\n",
      "\n",
      "[🔺] Top 3 highest RMSE files:\n",
      "  frame_00047.jpg: 0.36m\n",
      "  frame_00112.jpg: 0.34m\n",
      "  frame_00136.jpg: 0.30m\n",
      "\n",
      "[🔻] Top 3 lowest RMSE files:\n",
      "  frame_00059.jpg: 0.14m\n",
      "  frame_00133.jpg: 0.15m\n",
      "  frame_00103.jpg: 0.16m\n",
      "\n",
      "[📉] Top 3 lowest used keypoints:\n",
      "  frame_00001.jpg: 5 points\n",
      "  frame_00004.jpg: 5 points\n",
      "  frame_00007.jpg: 5 points\n",
      "\n",
      "[ℹ] Average used keypoint ratio: 100.00% (160/160)\n",
      "\n",
      "[!] Failed images due to invalid keypoints: 0\n"
     ]
    }
   ],
   "source": [
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Naju_90m_ChangeDetection_workspace/trial5\"\n",
    "height_m = 90\n",
    "prefix_a = \"initial_paired_\"\n",
    "prefix_b = \"new_\"\n",
    "down_a = 1\n",
    "down_b = 1\n",
    "testset = \"nerf_cd_pair\"\n",
    "\n",
    "homography_dir = os.path.join(workspace_dir, f\"CD_PAIR/nerf_cd_pair_rectified/homography\") # For gps version\n",
    "\n",
    "if down_a == 1:\n",
    "    initial_features_path = os.path.join(workspace_dir, f'CD_PAIR/{testset}/initial_paired_features.json')\n",
    "else:\n",
    "    initial_features_path = os.path.join(workspace_dir, f'CD_PAIR/{testset}/initial_paired_features_{down_a}.json')\n",
    "\n",
    "if down_b == 1:\n",
    "    new_features_path = os.path.join(workspace_dir, 'CD_PAIR/new_features.json')\n",
    "else:\n",
    "    new_features_path = os.path.join(workspace_dir, f'CD_PAIR/new_features_{down_b}.json')\n",
    "\n",
    "transforms_path = os.path.join(workspace_dir, \"initial/ns_processed/transforms.json\")\n",
    "\n",
    "\n",
    "compare_features(initial_features_path, new_features_path, transforms_path, height_m = height_m, down_a = down_a, down_b = down_b, prefix_a = prefix_a, prefix_b = prefix_b, homography_dir = homography_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c84346",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Sintanjin_80m_CD_workspace/longlong_trial1\"\n",
    "initial_features_path = os.path.join(workspace_dir, 'CD_PAIR/correspondence_search_nerf_cd_pair_filter/initial_paired_features.json')\n",
    "new_features_path = os.path.join(workspace_dir, 'CD_PAIR/correspondence_search_nerf_cd_pair_filter/features.json')\n",
    "transforms_path = os.path.join(workspace_dir, \"initial/ns_processed/transforms.json\")\n",
    "\n",
    "height_m = 80\n",
    "\n",
    "compare_features(initial_features_path, new_features_path, transforms_path, height_m = height_m, downscale_factor = 2,  prefix_a=\"initial_paired_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6001a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Sintanjin_80m_CD_workspace/longlong_trial1\"\n",
    "initial_features_path = os.path.join(workspace_dir, 'CD_PAIR/baseline_cd_pair_filter/initial_paired_features.json')\n",
    "new_features_path = os.path.join(workspace_dir, 'CD_PAIR/baseline_cd_pair_filter/features.json')\n",
    "transforms_path = os.path.join(workspace_dir, \"initial/ns_processed/transforms.json\")\n",
    "\n",
    "height_m = 80\n",
    "compare_features(initial_features_path, new_features_path, transforms_path, height_m = height_m, downscale_factor = 1, prefix_a=\"initial_paired_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cbdb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Sintanjin_80m_CD_workspace/longlong_trial1\"\n",
    "initial_features_path = os.path.join(workspace_dir, 'CD_PAIR/baseline_cd_pair2_filter/initial_paired_features.json')\n",
    "new_features_path = os.path.join(workspace_dir, 'CD_PAIR/baseline_cd_pair2_filter/features.json')\n",
    "transforms_path = os.path.join(workspace_dir, \"initial/ns_processed/transforms.json\")\n",
    "\n",
    "height_m = 80\n",
    "compare_features(initial_features_path, new_features_path, transforms_path, height_m = height_m, downscale_factor = 1, prefix_a=\"initial_paired_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def rectify(image1: np.ndarray, image2: np.ndarray, resize_factor: float, resize_image_func) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Rectify the initial image to align with the new image using homography.\n",
    "\n",
    "    Args:\n",
    "        image1 (np.ndarray): Initial image.\n",
    "        image2 (np.ndarray): New image to align with.\n",
    "        resize_factor (float): Factor by which to resize images before processing.\n",
    "        resize_image_func (function): Function to resize an image and return the resized image and scale.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]: \n",
    "            The corrected initial image, corrected new image, and the homography matrix.\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    img1 = cv2.cvtColor(image1.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(image2.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img1_resize, scale1 = resize_image_func(img1, resize_factor)\n",
    "    img2_resize, scale2 = resize_image_func(img2, resize_factor)\n",
    "\n",
    "    kp1, des1 = sift.detectAndCompute(img1_resize, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2_resize, None)\n",
    "\n",
    "    if des1 is None or des2 is None:\n",
    "        raise ValueError(\"❌ No features found in one or both images.\")\n",
    "\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(des1, des2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "\n",
    "    if len(good_matches) < 10:\n",
    "        raise ValueError(f\"❌ Not enough good matches: {len(good_matches)}\")\n",
    "\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "    F, inliers = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, ransacReprojThreshold=3.0, confidence=0.99)\n",
    "    if inliers is None or inliers.sum() < 10:\n",
    "        raise ValueError(\"❌ Fundamental matrix estimation failed or too few inliers.\")\n",
    "\n",
    "    pts1 = pts1[inliers.ravel() == 1]\n",
    "    pts2 = pts2[inliers.ravel() == 1]\n",
    "\n",
    "    H_12, inliers = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "    if H_12 is None or inliers is None or inliers.sum() < 10:\n",
    "        raise ValueError(\"❌ Homography too unstable or insufficient inliers.\")\n",
    "\n",
    "    scale_matrix = np.eye(3)\n",
    "    scale_matrix[0, 0] = 1 / scale1\n",
    "    scale_matrix[1, 1] = 1 / scale1\n",
    "    homography_12 = scale_matrix @ H_12 @ np.linalg.inv(scale_matrix)\n",
    "\n",
    "    height, width, _ = image2.shape\n",
    "    corrected_image1 = cv2.warpPerspective(image1, homography_12, (width, height))\n",
    "\n",
    "    mask_warped = np.zeros_like(image1, dtype=np.uint8)\n",
    "    cv2.warpPerspective(np.ones_like(image1, dtype=np.uint8), homography_12, (width, height), dst=mask_warped, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "    corrected_image2 = image2 * mask_warped\n",
    "\n",
    "    return corrected_image1, corrected_image2, homography_12\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
