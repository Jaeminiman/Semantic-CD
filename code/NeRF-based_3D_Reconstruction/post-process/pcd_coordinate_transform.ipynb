{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLMAP-NeRFStudio ê°„ ì¢Œí‘œê³„ ë³€í™˜ ì‹¤í—˜ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# choice: Every transforms can be written as function or transformation matrix\n",
    "T_opengl2opencv = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "T_colmap2nerf = np.array([[1, 0, 0, 0], [0, 0, 1, 0], [0, -1, 0, 0], [0, 0, 0, 1]]) # applied_transform\n",
    "\n",
    "# convert between opencv and nerfstudio function version\n",
    "def colmap_to_nerfstudio(c2w):\n",
    "    # c2w: expected shape (4, 4)\n",
    "    c2w[..., 0:3, 1:3] *= -1 # flip the y_c, z_c axis (2D OPENCV -> OPENGL)\n",
    "\n",
    "    c2w = c2w[..., np.array([0, 2, 1, 3]), :] # exchange y, z (COLMAP -> NeRFStudio)\n",
    "    c2w[..., 2, :] *= -1 # flip z axis (COLMAP -> NeRFStudio)\n",
    "    return c2w\n",
    "\n",
    "# convert between opencv and nerfstudio matrix version\n",
    "def colmap_to_nerfstudio_matrix_ver(c2w):\n",
    "    # c2w: expected shape (4, 4)\n",
    "\n",
    "    T_opencv2colmap = c2w\n",
    "    T_colmap_opencv = T_opencv2colmap\n",
    "    \n",
    "    T_opencv_opengl = T_opengl2opencv\n",
    "    T_nerf_colmap = T_colmap2nerf    \n",
    "\n",
    "    T_nerf_opengl = T_nerf_colmap @ T_colmap_opencv @ T_opencv_opengl\n",
    "    T_opengl2nerf = T_nerf_opengl \n",
    "    c2w = T_opengl2nerf\n",
    "    return c2w\n",
    "\n",
    "# convert between opencv and opengl function version\n",
    "def opengl_to_opencv(c2w):\n",
    "    transform = np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]])\n",
    "    if isinstance(c2w, torch.Tensor):\n",
    "        transform = torch.Tensor(transform).to(c2w)\n",
    "    c2w[..., :3, :3] @= transform\n",
    "    return c2w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# [Test] coordinate transform (COLMAP -> NeRFStudio) evaluation\n",
    "q_colmap2opencv = np.array([0.995759,0.000310773,0.0178788,-0.0902497]) \n",
    "t_colmap2opencv = np.array([4.34879,-1.51327,-0.0316503])\n",
    "T_colmap2opencv = quaternion_to_transform_matrix(q_colmap2opencv, t_colmap2opencv) # T_cw\n",
    "T_opencv2colmap = np.linalg.inv(T_colmap2opencv) # c2w\n",
    "T_opengl2nerf = colmap_to_nerfstudio(T_opencv2colmap.copy())\n",
    "\n",
    "# test 1\n",
    "T_nerf_opengl = T_opengl2nerf\n",
    "T_opengl_opencv = np.linalg.inv(T_opengl2opencv)\n",
    "T_colmap_nerf = np.linalg.inv(T_colmap2nerf)\n",
    "T_colmap_opencv_pred = T_colmap_nerf@T_nerf_opengl@T_opengl_opencv\n",
    "T_opencv2colmap_pred = T_colmap_opencv_pred\n",
    "print(np.allclose(T_opencv2colmap, T_opencv2colmap_pred, atol=1e-5))\n",
    "\n",
    "# test 2\n",
    "T_opengl2nerf_pred = colmap_to_nerfstudio_matrix_ver(T_opencv2colmap.copy())\n",
    "\n",
    "print(np.allclose(T_opengl2nerf, T_opengl2nerf_pred, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Render] Transform cameras from transforms.json to camera_path.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale: 0.1889979446048152\n",
      "Transformation applied and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write Camera_path(opengl-NeRF to opengl-webgui)\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from R3DR.utils import dir_utils\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2\"\n",
    "nerfstudio_transforms_path = os.path.join(workspace_dir, \"new_correspondence/ns_processed/transforms.json\")\n",
    "webgui_camera_path = os.path.join(workspace_dir, \"new_correspondence/ns_processed/camera_path.json\")\n",
    "config_path = os.path.join(workspace_dir, \"new_correspondence/config/config.yaml\")\n",
    "fov = 40\n",
    "\n",
    "config = dir_utils.load_config(config_path)\n",
    "dir_utils.validate_config(config)\n",
    "\n",
    "# dataparser_transforms.json ì½ê¸°\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser = json.load(file)\n",
    "\n",
    "# ë³€í™˜ í–‰ë ¬ê³¼ ìŠ¤ì¼€ì¼ ê°€ì ¸ì˜¤ê¸°(ok)\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser['scale']\n",
    "print(f\"scale: {scale}\")\n",
    "\n",
    "# transforms.json ì½ê¸°\n",
    "with open(nerfstudio_transforms_path, 'r') as file:\n",
    "    transforms = json.load(file) # c2w\n",
    "\n",
    "T_nerf_colmap = homogeneous(np.array(transforms['applied_transform'])) # (4, 4), applied_transform(T_nerf_colmap)\n",
    "T_webgui_nerf =  T_webgui_colmap @ np.linalg.inv(T_nerf_colmap) # (4, 4) orient_pose_transform(T_webgui_nerf)\n",
    "\n",
    "# ëª¨ë“  í”„ë ˆì„ì— ëŒ€í•´ ë³€í™˜ ì ìš©\n",
    "for frame in transforms['frames']:\n",
    "\n",
    "    T_nerf_opengl = np.array(frame['transform_matrix']) # (4, 4)\n",
    "    \n",
    "\n",
    "    # ë³€í™˜ í–‰ë ¬ ì ìš©\n",
    "    T_webgui_opengl = T_webgui_nerf @ T_nerf_opengl     \n",
    "    T_webgui_opengl[:3, 3] *= scale\n",
    "    frame['transform_matrix'] = T_webgui_opengl.flatten().tolist()\n",
    "    \n",
    "\n",
    "sorted_frames = sorted(transforms['frames'], key=lambda frame: frame['file_path'])\n",
    "\n",
    "downscale_factor = int(config['nerf_settings']['ns_train_options']['dataparser_options']['downscale-factor'])\n",
    "\n",
    "w, h = [int(v / downscale_factor) for v in (sorted_frames[0]['w'], sorted_frames[0]['h'])]\n",
    "out = {\n",
    "        'camera_type': 'perspective',\n",
    "        'render_height': h,\n",
    "        'render_width': w,\n",
    "        'seconds': len(sorted_frames),\n",
    "        'camera_path': [\n",
    "                {'camera_to_world': frame['transform_matrix'], 'fov': fov, 'aspect': 1, 'file_path': frame['file_path']} for frame in sorted_frames\n",
    "            ]\n",
    "        }\n",
    "# ë³€ê²½ëœ ë‚´ìš©ì„ transforms.json íŒŒì¼ì— ë‹¤ì‹œ ì €ì¥\n",
    "with open(webgui_camera_path, 'w') as file:\n",
    "    json.dump(out, file, indent=4)\n",
    "print(\"Transformation applied and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation applied and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write camera_path(Opencv to ECEF)\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from plyfile import PlyData, PlyElement\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "import time\n",
    "\n",
    "T_opencv_opengl = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "ecef_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\"\n",
    "webgui_camera_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/ns_processed/camera_path.json\"\n",
    "\n",
    "output_ecef_camera_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/ns_processed/ecef_camera_path.json\"\n",
    "\n",
    "# dataparser_transforms.json ì½ê¸°\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "print(scale)\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„±\n",
    "# NeRFStudio Sim3 ì •ì˜ ìƒ, R, t ë¨¼ì € ì ìš© í›„ ì „ì²´ scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "\n",
    "# ecef_transforms.json ì½ê¸°\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„± (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "\n",
    "# camera_path.json ì½ê¸°\n",
    "with open(webgui_camera_path, 'r') as file:\n",
    "    camera_path_json = json.load(file)\n",
    "\n",
    "out = {\"frames\": []}\n",
    "for camera in camera_path_json['camera_path']:\n",
    "    T_webgui_opengl = np.array(camera['camera_to_world']).reshape(4, 4)\n",
    "    file_path = camera['file_path']\n",
    "\n",
    "    T_ecef_opencv = T_ecef_webgui_sim3 @ T_webgui_opengl @ np.linalg.inv(T_opencv_opengl)    \n",
    "\n",
    "    # retain orthonormal property of rotation\n",
    "    R_wc = T_ecef_opencv[:3, :3] \n",
    "    U, _, V_t = np.linalg.svd(R_wc)\n",
    "    R_wc_norm = U @ V_t\n",
    "    T_ecef_opencv[:3, :3] = R_wc_norm\n",
    "\n",
    "    out[\"frames\"].append({'file_path': file_path, 'camera_to_world': T_ecef_opencv.tolist()})\n",
    "\n",
    "# ë³€ê²½ëœ ë‚´ìš©ì„ transforms.json íŒŒì¼ì— ì €ì¥\n",
    "with open(output_ecef_camera_path, 'w') as file:\n",
    "    json.dump(out, file, indent=4)\n",
    "print(\"Transformation applied and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Geo-registration] Transform pcd/mesh from NeRFStudio to ECEF/UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataparser_transform in 0.00 seconds\n",
      "Loaded ECEF transform in 0.00 seconds\n",
      "Loaded PLY data in 2.01 seconds\n",
      "Converted to ECEF in 0.17 seconds\n",
      "Converted to UTM in 3.07 seconds\n",
      "Converted to central korea in 6.07 seconds\n",
      "ECEF Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_ecef.ply\n",
      "UTM Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_utm.ply\n",
      "ì¤‘ë¶€ì›ì  (EPSG:5186) Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_ck.pcd\n"
     ]
    }
   ],
   "source": [
    "# NeRFStudio(WebGUI) pcd -> ECEF/UTM Geo-registered pcd\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "import time\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def normalize_coordinates(coords):\n",
    "    \"\"\"\n",
    "    ì¢Œí‘œ ë°°ì—´ì—ì„œ ê° ì¶•ì˜ í‰ê· ì„ ê³„ì‚°í•œ í›„, ì´ë¥¼ ì›ë˜ ì¢Œí‘œì—ì„œ ëº€ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "        coords (numpy.ndarray): (n, 3) í˜•íƒœì˜ ì¢Œí‘œ ë°°ì—´.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: í‰ê· ì´ ì œê±°ëœ (n, 3) í˜•íƒœì˜ ì¢Œí‘œ ë°°ì—´.\n",
    "    \"\"\"\n",
    "    mean_coords = np.mean(coords, axis=0)  # ê° ì¶•(x, y, z)ì˜ í‰ê·  ê³„ì‚°\n",
    "    normalized_coords = coords - mean_coords  # í‰ê· ì„ ë¹¼ì„œ ì›ì  ê¸°ì¤€ ì •ê·œí™”\n",
    "    return normalized_coords, mean_coords\n",
    "    \n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for ECEF to UTM conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to UTM coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    points_utm = np.stack([e, n, alt], axis = -1) \n",
    "    \n",
    "    return np.array(points_utm)\n",
    "\n",
    "def ecef_to_central_korea_transformer():\n",
    "    \"\"\"Creates a Transformer for ECEF to EPSG:5186 (ì¤‘ë¶€ì›ì ) conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", \"EPSG:5186\", always_xy=True)\n",
    "\n",
    "def ecef_to_central_korea_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to ì¤‘ë¶€ì›ì  (EPSG:5186) coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "    \n",
    "##############################################################################################################################################\n",
    "# User Input\n",
    "##############################################################################################################################################\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial\"\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "##############################################################################################################################################\n",
    "ecef_transforms_path = os.path.join(workspace_dir, \"ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\")\n",
    "\n",
    "ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/point_cloud.ply\")\n",
    "\n",
    "output_dir = os.path.join(workspace_dir, \"nerf_output/exports/pcd/original\")\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ECEF Geo-registered PLY ì €ì¥ ê²½ë¡œ\n",
    "output_ecef_ply_path = os.path.join(output_dir, \"point_cloud_ecef.ply\")\n",
    "\n",
    "# UTM Geo-registered PLY ì €ì¥ ê²½ë¡œ\n",
    "output_utm_ply_path = os.path.join(output_dir, \"point_cloud_utm.ply\")\n",
    "\n",
    "# CK Geo-registered PLY ì €ì¥ ê²½ë¡œ\n",
    "output_ck_ply_path = os.path.join(output_dir, \"point_cloud_ck.ply\")\n",
    "\n",
    "# output_ck_translation_path = os.path.join(workspace_dir, \"translation_ck.json\")\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# dataparser_transforms.json ì½ê¸°\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„±\n",
    "# NeRFStudio Sim3 ì •ì˜ ìƒ, R, t ë¨¼ì € ì ìš© í›„ ì „ì²´ scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "print(f\"Loaded dataparser_transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ecef_transforms.json ì½ê¸°\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„± (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "\n",
    "print(f\"Loaded ECEF transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# .ply íŒŒì¼ ì½ê¸°\n",
    "pcd = o3d.io.read_point_cloud(ply_path)\n",
    "points = np.asarray(pcd.points)  # í¬ì¸íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "print(f\"Loaded PLY data in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "# ECEF ë³€í™˜\n",
    "coords = np.hstack([points, np.ones((points.shape[0], 1))])  # (N, 4)\n",
    "assert(coords.dtype == np.float64)\n",
    "\n",
    "coords_ecef = (T_ecef_webgui_sim3[:3, :] @ coords.T).T  # ECEF ë³€í™˜ ì¢Œí‘œ (x', y', z')\n",
    "\n",
    "print(f\"Converted to ECEF in {time.time() - start_time:.2f} seconds\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert ECEF to UTM\n",
    "transformer = ecef_to_utm_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_utm = ecef_to_utm_points(coords_ecef, transformer)\n",
    "\n",
    "print(f\"Converted to UTM in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# ì¤‘ë¶€ì›ì  ë³€í™˜\n",
    "transformer_central_korea = ecef_to_central_korea_transformer()\n",
    "coords_ck = ecef_to_central_korea_points(coords_ecef, transformer_central_korea)\n",
    "print(f\"Converted to central korea in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# ECEF PCD ê°ì²´ ìƒì„±\n",
    "ecef_pcd = o3d.geometry.PointCloud()\n",
    "ecef_pcd.points = o3d.utility.Vector3dVector(coords_ecef)  # ECEF ì¢Œí‘œ (x, y, z)\n",
    "if colors is not None:\n",
    "    ecef_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "if normals is not None:\n",
    "    ecef_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# UTM PCD ê°ì²´ ìƒì„±\n",
    "utm_pcd = o3d.geometry.PointCloud()\n",
    "utm_pcd.points = o3d.utility.Vector3dVector(coords_utm)  # UTM ì¢Œí‘œ (x, y, z)\n",
    "if colors is not None:\n",
    "    utm_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "if normals is not None:\n",
    "    utm_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# ì¤‘ë¶€ì›ì  PCD ê°ì²´ ìƒì„±\n",
    "# coords_ck, ck_global_translation = normalize_coordinates(coords_ck)\n",
    "\n",
    "ck_pcd = o3d.geometry.PointCloud()\n",
    "ck_pcd.points = o3d.utility.Vector3dVector(coords_ck)\n",
    "if colors is not None:\n",
    "    ck_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "if normals is not None:\n",
    "    ck_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "# mean_dict = {\"global_translation\": ck_global_translation.tolist()}\n",
    "\n",
    "# with open(output_ck_translation_path, \"w\") as f:\n",
    "#     json.dump(mean_dict, f, indent=4)  # JSON íŒŒì¼ë¡œ ì €ì¥ (ë“¤ì—¬ì“°ê¸° í¬í•¨)\n",
    "\n",
    "# ECEF .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "o3d.io.write_point_cloud(output_ecef_ply_path, ecef_pcd)\n",
    "print(f\"ECEF Transformed point cloud saved to: {output_ecef_ply_path}\")\n",
    "\n",
    "# UTM .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "o3d.io.write_point_cloud(output_utm_ply_path, utm_pcd)\n",
    "print(f\"UTM Transformed point cloud saved to: {output_utm_ply_path}\")\n",
    "\n",
    "# ì¤‘ë¶€ì›ì  PLY ì €ì¥\n",
    "o3d.io.write_point_cloud(output_ck_ply_path, ck_pcd)\n",
    "print(f\"ì¤‘ë¶€ì›ì  (EPSG:5186) Transformed point cloud saved to: {output_ck_ply_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ECEF transform in 0.00 seconds\n",
      "Loaded PLY data in 1.71 seconds\n",
      "Converted to UTM in 2.94 seconds\n",
      "Converted to central korea in 2.62 seconds\n",
      "Converted to NeRFStudio(WebGUI) in 0.03 seconds\n",
      "ì¤‘ë¶€ì›ì  (EPSG:5186) Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/filtered/filtered_ck.pcd\n",
      "webgui Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/filtered/filtered_webgui.pcd\n"
     ]
    }
   ],
   "source": [
    "# UTM Geo-registered pcd(Filtered PCD) -> NeRFStudio(WebGUI) pcd(For mesh generation and filtered central pcd)\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer, CRS\n",
    "import time\n",
    "import open3d as o3d\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "def normalize_coordinates(coords):\n",
    "    \"\"\"\n",
    "    ì¢Œí‘œ ë°°ì—´ì—ì„œ ê° ì¶•ì˜ í‰ê· ì„ ê³„ì‚°í•œ í›„, ì´ë¥¼ ì›ë˜ ì¢Œí‘œì—ì„œ ëº€ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "        coords (numpy.ndarray): (n, 3) í˜•íƒœì˜ ì¢Œí‘œ ë°°ì—´.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: í‰ê· ì´ ì œê±°ëœ (n, 3) í˜•íƒœì˜ ì¢Œí‘œ ë°°ì—´.\n",
    "    \"\"\"\n",
    "    mean_coords = np.mean(coords, axis=0)  # ê° ì¶•(x, y, z)ì˜ í‰ê·  ê³„ì‚°\n",
    "    normalized_coords = coords - mean_coords  # í‰ê· ì„ ë¹¼ì„œ ì›ì  ê¸°ì¤€ ì •ê·œí™”\n",
    "    return normalized_coords, mean_coords\n",
    "\n",
    "def ecef_to_central_korea_transformer():\n",
    "    \"\"\"Creates a Transformer for ECEF to EPSG:5186 (ì¤‘ë¶€ì›ì ) conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", \"EPSG:5186\", always_xy=True)\n",
    "\n",
    "def ecef_to_central_korea_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to ì¤‘ë¶€ì›ì  (EPSG:5186) coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "\n",
    "def utm_to_ecef_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for UTM to ECEF conversion.\"\"\"\n",
    "    south = \" +south\" if zone_letter == \"S\" else \"\"  # ë‚¨ë°˜êµ¬ ì„¤ì •\n",
    "    utm_crs = CRS.from_proj4(f\"+proj=utm +zone={zone_number}{south} +datum=WGS84 +units=m +no_defs\")\n",
    "    \n",
    "    transformer_utm_to_ecef = Transformer.from_crs(utm_crs, \"EPSG:4978\", always_xy=True)\n",
    "    return transformer_utm_to_ecef  # ì˜¬ë°”ë¥´ê²Œ ë³€í™˜ê¸°ë¥¼ ë°˜í™˜\n",
    "\n",
    "def utm_to_ecef_points(points_utm: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UTM (easting, northing, altitude) ì¢Œí‘œë¥¼ ECEF ì¢Œí‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    points_utm : (N, 3)\n",
    "    transformer : UTM->ECEF ë³€í™˜ì„ ìœ„í•œ pyproj Transformer\n",
    "    \"\"\"\n",
    "    # UTM ì¢Œí‘œ: (easting, northing, altitude)\n",
    "    east, north, alt = points_utm[:, 0], points_utm[:, 1], points_utm[:, 2]\n",
    "    # Transformer.transformì˜ ì…ë ¥ ìˆœì„œëŠ” (x, y, z) ì¦‰, (east, north, alt)\n",
    "    x, y, z = transformer.transform(east, north, alt)\n",
    "    points_ecef = np.stack([x, y, z], axis=-1)\n",
    "    return points_ecef\n",
    "\n",
    "##############################################################################################################################################\n",
    "# User Input\n",
    "##############################################################################################################################################\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial\"\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "##############################################################################################################################################\n",
    "ecef_transforms_path = os.path.join(workspace_dir, \"ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\")\n",
    "\n",
    "utm_ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/filtered_utm.ply\")\n",
    "\n",
    "output_webgui_ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/filtered_webgui.pcd\")\n",
    "\n",
    "output_ck_ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/filtered_ck.pcd\")\n",
    "output_ck_translation_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/translation_ck.json\")\n",
    "\n",
    "# dataparser_transforms.json ì½ê¸°\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„±\n",
    "# NeRFStudio Sim3 ì •ì˜ ìƒ, R, t ë¨¼ì € ì ìš© í›„ ì „ì²´ scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ecef_transforms.json ì½ê¸°\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„± (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "T_webgui_ecef_sim3 = np.linalg.inv(T_ecef_webgui_sim3)\n",
    "\n",
    "print(f\"Loaded ECEF transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# .ply íŒŒì¼ ì½ê¸°\n",
    "pcd = o3d.io.read_point_cloud(utm_ply_path)\n",
    "coords_utm = np.asarray(pcd.points)  # í¬ì¸íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "assert(coords_utm.dtype == np.float64)\n",
    "colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "print(f\"Loaded PLY data in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert UTM to ECEF\n",
    "transformer = utm_to_ecef_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_ecef = utm_to_ecef_points(coords_utm, transformer)\n",
    "coords_ecef = np.hstack([coords_ecef, np.ones((coords_ecef.shape[0], 1))])  # (N, 4)\n",
    "print(f\"Converted to UTM in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# ì¤‘ë¶€ì›ì  ë³€í™˜\n",
    "start_time = time.time()\n",
    "transformer_central_korea = ecef_to_central_korea_transformer()\n",
    "coords_ck = ecef_to_central_korea_points(coords_ecef, transformer_central_korea)\n",
    "print(f\"Converted to central korea in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert ECEF to WebGUI\n",
    "coords_webgui = (T_webgui_ecef_sim3[:3, :] @ coords_ecef.T).T\n",
    "\n",
    "print(f\"Converted to NeRFStudio(WebGUI) in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# WebGUI PCD ê°ì²´ ìƒì„±\n",
    "webgui_pcd = o3d.geometry.PointCloud()\n",
    "webgui_pcd.points = o3d.utility.Vector3dVector(coords_webgui)  # ECEF ì¢Œí‘œ (x, y, z)\n",
    "if colors is not None:\n",
    "    webgui_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "if normals is not None:\n",
    "    webgui_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# ì¤‘ë¶€ì›ì  PCD ê°ì²´ ìƒì„±\n",
    "ck_pcd = o3d.geometry.PointCloud()\n",
    "coords_ck, ck_global_translation = normalize_coordinates(coords_ck)\n",
    "ck_pcd.points = o3d.utility.Vector3dVector(coords_ck)\n",
    "if colors is not None:\n",
    "    ck_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "if normals is not None:\n",
    "    ck_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# ì¤‘ë¶€ì›ì  PLY ì €ì¥\n",
    "o3d.io.write_point_cloud(output_ck_ply_path, ck_pcd)\n",
    "print(f\"ì¤‘ë¶€ì›ì  (EPSG:5186) Transformed point cloud saved to: {output_ck_ply_path}\")\n",
    "\n",
    "mean_dict = {\"global_translation\": ck_global_translation.tolist()}\n",
    "\n",
    "with open(output_ck_translation_path, \"w\") as f:\n",
    "    json.dump(mean_dict, f, indent=4)  # JSON íŒŒì¼ë¡œ ì €ì¥ (ë“¤ì—¬ì“°ê¸° í¬í•¨)\n",
    "\n",
    "\n",
    "# ECEF .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "o3d.io.write_point_cloud(output_webgui_ply_path, webgui_pcd)\n",
    "print(f\"webgui Transformed point cloud saved to: {output_webgui_ply_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Loaded dataparser_transform in 0.01 seconds\n",
      "Loaded ECEF transform in 0.00 seconds\n",
      "Maximum in inverse_indices: 208191\n",
      "Original Vertex Shape: (342598, 3)\n",
      "New Vertex Shape: (208192, 3)\n",
      "Loaded OBJ mesh in 10.77 seconds\n",
      "Converted to ECEF in 2099.12 seconds\n",
      "Converted to UTM in 0.12 seconds\n",
      "Converted to central korea in 0.14 seconds\n",
      "ECEF Transformed mesh saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/mesh_ecef.obj\n",
      "UTM Transformed mesh saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/mesh_utm.obj\n",
      "CK Transformed mesh saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/mesh_ck.obj\n",
      "Saved transformed meshes in 39.27 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3D NeRFStudio mesh -> ECEF/UTM Translation\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "import time\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import os\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for ECEF to UTM conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to UTM coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    points_utm = np.stack([e, n, alt], axis = -1) \n",
    "    \n",
    "    return points_utm\n",
    "\n",
    "def ecef_to_central_korea_transformer():\n",
    "    \"\"\"Creates a Transformer for ECEF to EPSG:5186 (ì¤‘ë¶€ì›ì ) conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", \"EPSG:5186\", always_xy=True)\n",
    "\n",
    "def ecef_to_central_korea_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to ì¤‘ë¶€ì›ì  (EPSG:5186) coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "\n",
    "def ecef_to_enu_rotation_matrix(lat_deg, lon_deg):\n",
    "    \"\"\"\n",
    "    ìœ„ë„/ê²½ë„ë¡œ ì •ì˜ëœ ENU ê¸°ì¤€ ì¢Œí‘œê³„ì— ëŒ€í•œ ECEF â†’ ENU íšŒì „ í–‰ë ¬ ìƒì„±\n",
    "    \"\"\"\n",
    "    lat = np.radians(lat_deg)\n",
    "    lon = np.radians(lon_deg)\n",
    "\n",
    "    R = np.array([\n",
    "        [-np.sin(lon),              np.cos(lon),              0],\n",
    "        [-np.sin(lat)*np.cos(lon), -np.sin(lat)*np.sin(lon), np.cos(lat)],\n",
    "        [np.cos(lat)*np.cos(lon),  np.cos(lat)*np.sin(lon),  np.sin(lat)]\n",
    "    ])\n",
    "    return R  # 3x3 matrix\n",
    "\n",
    "\n",
    "def ecef_to_latlonalt(x, y, z):\n",
    "    transformer = Transformer.from_crs(\"epsg:4978\", \"epsg:4326\", always_xy=True)  # ECEF â†’ WGS84\n",
    "    lon, lat, alt = transformer.transform(x, y, z)\n",
    "    return lat, lon, alt\n",
    "\n",
    "def normalize_coordinates(coords):\n",
    "    \"\"\"\n",
    "    ì¢Œí‘œ ë°°ì—´ì—ì„œ ê° ì¶•ì˜ í‰ê· ì„ ê³„ì‚°í•œ í›„, ì´ë¥¼ ì›ë˜ ì¢Œí‘œì—ì„œ ëº€ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "        coords (numpy.ndarray): (n, 3) í˜•íƒœì˜ ì¢Œí‘œ ë°°ì—´.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: í‰ê· ì´ ì œê±°ëœ (n, 3) í˜•íƒœì˜ ì¢Œí‘œ ë°°ì—´.\n",
    "    \"\"\"\n",
    "    mean_coords = np.mean(coords, axis=0)  # ê° ì¶•(x, y, z)ì˜ í‰ê·  ê³„ì‚°\n",
    "    normalized_coords = coords - mean_coords  # í‰ê· ì„ ë¹¼ì„œ ì›ì  ê¸°ì¤€ ì •ê·œí™”\n",
    "    return normalized_coords, mean_coords\n",
    "\n",
    "\n",
    "# Open3Dì˜ mesh loadì‹œ, Vertex ì¤‘ë³µ ë¬¸ì œë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•¨(Texture mappingì„ ìœ„í•œ ì½”ë“œ)\n",
    "def remove_duplicate_vertices(mesh):\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    triangles = np.asarray(mesh.triangles)\n",
    "    triangle_uvs = np.asarray(mesh.triangle_uvs)\n",
    "    vertex_normals = np.asarray(mesh.vertex_normals)\n",
    "    \n",
    "    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ dict (ìˆœì„œ ë³´ì¡´) np.uniqueëŠ” ìë™ sortë˜ì–´ ìˆœì„œê¸°ë°˜ mappingì´ ê¹¨ì§\n",
    "    unique_vertex_map = {}  \n",
    "    new_vertices = []\n",
    "    inverse_indices = np.zeros(len(vertices), dtype=int)\n",
    "\n",
    "    for i, v in enumerate(vertices):\n",
    "        v_tuple = tuple(v)  # ë¦¬ìŠ¤íŠ¸ë¥¼ íŠœí”Œë¡œ ë³€í™˜ (ë”•ì…”ë„ˆë¦¬ keyë¡œ ì‚¬ìš©)\n",
    "        if v_tuple not in unique_vertex_map:\n",
    "            unique_vertex_map[v_tuple] = len(new_vertices)\n",
    "            new_vertices.append(v)\n",
    "        inverse_indices[i] = unique_vertex_map[v_tuple]\n",
    "    print(f\"Maximum in inverse_indices: {np.max(inverse_indices)}\")\n",
    "    new_vertices = np.array(new_vertices)\n",
    "    new_triangles = inverse_indices[triangles]\n",
    "    assert triangles.shape == new_triangles.shape # ì‹¤ì œë¡œ ì¤‘ë³µëœ ë©´ì€ ì—†ë‹¤.\n",
    "\n",
    "    new_triangle_uvs = triangle_uvs.copy()\n",
    "    new_triangle_uvs[:, 1] = 1.0 - new_triangle_uvs[:, 1]  # Yì¶• ë’¤ì§‘ê¸° (Open3Dì™€ ë‹¤ë¥¸ mesh ì†Œí”„íŠ¸ì›¨ì–´ ê°„ UV ì •ì˜ ì°¨ì´ ë³´ì •)\n",
    "\n",
    "    \n",
    "    print(f\"Original Vertex Shape: {vertices.shape}\")\n",
    "    print(f\"New Vertex Shape: {new_vertices.shape}\")\n",
    "\n",
    "    # ì •ì  ë³‘í•© í›„, ë²•ì„  í‰ê·  ì²˜ë¦¬\n",
    "    new_normals = np.zeros_like(new_vertices, dtype=np.float64)\n",
    "    normal_counts = np.zeros(len(new_vertices), dtype=int)\n",
    "\n",
    "    for old_idx, new_idx in enumerate(inverse_indices):\n",
    "        new_normals[new_idx] += vertex_normals[old_idx]\n",
    "        normal_counts[new_idx] += 1\n",
    "\n",
    "    new_normals /= normal_counts[:, None]  # ì •ê·œí™”        \n",
    "    \n",
    "    # Open3D mesh ê°±ì‹ \n",
    "    new_mesh = o3d.geometry.TriangleMesh()\n",
    "    new_mesh.vertices = o3d.utility.Vector3dVector(new_vertices)\n",
    "    new_mesh.triangles = o3d.utility.Vector3iVector(new_triangles)\n",
    "    new_mesh.triangle_uvs = o3d.utility.Vector2dVector(new_triangle_uvs)\n",
    "    new_mesh.vertex_normals = o3d.utility.Vector3dVector(new_normals)\n",
    "    \n",
    "    return new_mesh\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ“Œ .OBJ ë©”ì‰¬ íŒŒì¼ ë³€í™˜ ì½”ë“œ\n",
    "# -------------------------------\n",
    "def transform_mesh_obj(input_obj_path, texture_path, output_path, T_ecef_webgui_sim3, zone_number=52, zone_letter=\"north\"):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_ecef_obj_path = os.path.join(output_path, \"mesh_ecef.obj\")\n",
    "    output_utm_obj_path = os.path.join(output_path, \"mesh_utm.obj\")\n",
    "    output_ck_obj_path = os.path.join(output_path, \"mesh_ck.obj\")\n",
    "    output_ecef_translation_path = os.path.join(output_path, \"translation_ecef.json\")\n",
    "    output_utm_translation_path = os.path.join(output_path, \"translation_utm.json\")\n",
    "    output_ck_translation_path = os.path.join(output_path, \"translation_ck.json\")\n",
    "\n",
    "    # 1ï¸âƒ£ .OBJ íŒŒì¼ ë¡œë“œ\n",
    "    mesh = o3d.io.read_triangle_mesh(input_obj_path) \n",
    "    \n",
    "    new_mesh = remove_duplicate_vertices(mesh)   \n",
    "\n",
    "    image = o3d.io.read_image(texture_path)  # í…ìŠ¤ì²˜ ë¡œë“œ\n",
    "    new_mesh.textures = [o3d.geometry.Image(image)]  # í…ìŠ¤ì²˜ ì ìš©\n",
    "\n",
    "    vertices = np.asarray(new_mesh.vertices)    \n",
    "    normals = np.asarray(new_mesh.vertex_normals)\n",
    "    \n",
    "    print(f\"Loaded OBJ mesh in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 2ï¸âƒ£ ECEF ë³€í™˜ ì ìš©\n",
    "    start_time = time.time()\n",
    "    coords = np.hstack([vertices, np.ones((vertices.shape[0], 1))])  # (N, 4)\n",
    "    normals_homo = np.hstack([normals, np.zeros((normals.shape[0], 1))])  # (N, 4)\n",
    "    assert coords.dtype == np.float64\n",
    "    \n",
    "    coords_ecef = (T_ecef_webgui_sim3[:3, :] @ coords.T).T  # ECEF ì¢Œí‘œ ë³€í™˜ (N, 3)\n",
    "    normals_ecef = (T_ecef_webgui_sim3[:3, :] @ normals_homo.T).T  # ECEF ì¢Œí‘œ ë³€í™˜ (N, 3)\n",
    "    normals_ecef /=  np.linalg.norm(normals_ecef)\n",
    "\n",
    "    latlonalts = []\n",
    "    for x, y, z in coords_ecef:\n",
    "        latlonalts.append(ecef_to_latlonalt(x, y, z))    \n",
    "    latlonalts = np.asarray(latlonalts) # (N, 3)\n",
    "\n",
    "    normals_enu = []\n",
    "    for (lat, lon, alt), normal_ecef in zip(latlonalts, normals_ecef):\n",
    "        R_ecef2enu = ecef_to_enu_rotation_matrix(lat, lon)\n",
    "        normals_enu.append(R_ecef2enu @ normal_ecef)\n",
    "\n",
    "    print(f\"Converted to ECEF in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 3ï¸âƒ£ ECEF â†’ UTM ë³€í™˜\n",
    "    start_time = time.time()\n",
    "    transformer = ecef_to_utm_transformer(zone_number, zone_letter)\n",
    "    coords_utm = ecef_to_utm_points(coords_ecef, transformer)\n",
    "\n",
    "    print(f\"Converted to UTM in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # ì¤‘ë¶€ì›ì  ë³€í™˜\n",
    "    start_time = time.time()\n",
    "    transformer_central_korea = ecef_to_central_korea_transformer()\n",
    "    coords_ck = ecef_to_central_korea_points(coords_ecef, transformer_central_korea)\n",
    "    print(f\"Converted to central korea in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 4ï¸âƒ£ ë³€í™˜ëœ ì¢Œí‘œë¥¼ Open3D Meshë¡œ ì €ì¥\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ECEF ë³€í™˜ í›„ ì €ì¥\n",
    "    ecef_mesh = copy.deepcopy(new_mesh)\n",
    "    coords_ecef, ecef_global_translation = normalize_coordinates(coords_ecef)\n",
    "    ecef_mesh.vertices = o3d.utility.Vector3dVector(coords_ecef)    \n",
    "    ecef_mesh.vertex_normals = o3d.utility.Vector3dVector(normals_ecef)    \n",
    "    o3d.io.write_triangle_mesh(output_ecef_obj_path, ecef_mesh, \n",
    "        write_ascii=True,\n",
    "        compressed=False,      # ì••ì¶• ì—†ì´ ì €ì¥ (ì •ë°€ë„ ìœ ì§€)\n",
    "        write_vertex_normals=True,  # ë²•ì„  í¬í•¨\n",
    "        write_vertex_colors=False,  # ìƒ‰ìƒ í¬í•¨ X (í•„ìš”í•œ ê²½ìš° True)\n",
    "        write_triangle_uvs=True     # UV ì¢Œí‘œ ê°•ì œ í¬í•¨\n",
    "    )\n",
    "    mean_dict = {\"global_translation\": ecef_global_translation.tolist()}\n",
    "\n",
    "    with open(output_ecef_translation_path, \"w\") as f:\n",
    "        json.dump(mean_dict, f, indent=4)  # JSON íŒŒì¼ë¡œ ì €ì¥ (ë“¤ì—¬ì“°ê¸° í¬í•¨)\n",
    "    \n",
    "    print(f\"ECEF Transformed mesh saved to: {output_ecef_obj_path}\")\n",
    "\n",
    "    # UTM ë³€í™˜ í›„ ì €ì¥\n",
    "    utm_mesh = copy.deepcopy(new_mesh)    \n",
    "    coords_utm, utm_global_translation = normalize_coordinates(coords_utm)\n",
    "    utm_mesh.vertices = o3d.utility.Vector3dVector(coords_utm)        \n",
    "    utm_mesh.vertex_normals = o3d.utility.Vector3dVector(normals_enu)\n",
    "    o3d.io.write_triangle_mesh(output_utm_obj_path, utm_mesh, \n",
    "        write_ascii=True,\n",
    "        compressed=False,      # ì••ì¶• ì—†ì´ ì €ì¥ (ì •ë°€ë„ ìœ ì§€)\n",
    "        write_vertex_normals=True,  # ë²•ì„  í¬í•¨\n",
    "        write_vertex_colors=False,  # ìƒ‰ìƒ í¬í•¨ X (í•„ìš”í•œ ê²½ìš° True)\n",
    "        write_triangle_uvs=True     # UV ì¢Œí‘œ ê°•ì œ í¬í•¨\n",
    "    )\n",
    "    mean_dict = {\"global_translation\": utm_global_translation.tolist()}\n",
    "\n",
    "    with open(output_utm_translation_path, \"w\") as f:\n",
    "        json.dump(mean_dict, f, indent=4)  # JSON íŒŒì¼ë¡œ ì €ì¥ (ë“¤ì—¬ì“°ê¸° í¬í•¨)\n",
    "        \n",
    "    print(f\"UTM Transformed mesh saved to: {output_utm_obj_path}\")\n",
    "\n",
    "    # CK ë³€í™˜ í›„ ì €ì¥\n",
    "    ck_mesh = copy.deepcopy(new_mesh)    \n",
    "    coords_ck, ck_global_translation = normalize_coordinates(coords_ck)\n",
    "    ck_mesh.vertices = o3d.utility.Vector3dVector(coords_ck)        \n",
    "    ck_mesh.vertex_normals = o3d.utility.Vector3dVector(normals_enu)\n",
    "    o3d.io.write_triangle_mesh(output_ck_obj_path, ck_mesh, \n",
    "        write_ascii=True,\n",
    "        compressed=False,      # ì••ì¶• ì—†ì´ ì €ì¥ (ì •ë°€ë„ ìœ ì§€)\n",
    "        write_vertex_normals=True,  # ë²•ì„  í¬í•¨\n",
    "        write_vertex_colors=False,  # ìƒ‰ìƒ í¬í•¨ X (í•„ìš”í•œ ê²½ìš° True)\n",
    "        write_triangle_uvs=True     # UV ì¢Œí‘œ ê°•ì œ í¬í•¨\n",
    "    )\n",
    "    mean_dict = {\"global_translation\": ck_global_translation.tolist()}\n",
    "\n",
    "    with open(output_ck_translation_path, \"w\") as f:\n",
    "        json.dump(mean_dict, f, indent=4)  # JSON íŒŒì¼ë¡œ ì €ì¥ (ë“¤ì—¬ì“°ê¸° í¬í•¨)\n",
    "        \n",
    "    print(f\"CK Transformed mesh saved to: {output_ck_obj_path}\")\n",
    "\n",
    "    print(f\"Saved transformed meshes in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/ns_processed/nerfacto/2025-05-08_071846/dataparser_transforms.json\"\n",
    "ecef_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\"\n",
    "\n",
    "obj_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/mesh.obj\"\n",
    "\n",
    "texture_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/material_0.png\"  # í…ìŠ¤ì²˜ íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "output_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# dataparser_transforms.json ì½ê¸°\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„±\n",
    "# NeRFStudio Sim3 ì •ì˜ ìƒ, R, t ë¨¼ì € ì ìš© í›„ ì „ì²´ scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "print(f\"Loaded dataparser_transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ecef_transforms.json ì½ê¸°\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) ë³€í™˜ í–‰ë ¬ ìƒì„± (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "\n",
    "print(f\"Loaded ECEF transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "transform_mesh_obj(obj_path, texture_path, output_path, T_ecef_webgui_sim3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCD Post-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9998607 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_utm.ply\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# .ply íŒŒì¼ ë¡œë“œ\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial\"\n",
    "input_ply_path = os.path.join(workspace_dir,'nerf_output/exports/pcd/original/point_cloud_utm.ply')\n",
    "\n",
    "# ì €ì¥í•  .ply íŒŒì¼ ê²½ë¡œ\n",
    "output_dir = os.path.join(workspace_dir,'nerf_output/exports/pcd/filtered')\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_ply_path = os.path.join(output_dir, 'filtered_utm.ply')\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "print(f\"Loaded {len(pcd.points)} points from {input_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No filtering applied. Total points: 9998607\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ====== í•¨ìˆ˜ ì •ì˜ ======\n",
    "def filter_points_in_polygon(point_cloud_xy, polygon_xy):\n",
    "    polygon = Polygon(polygon_xy)\n",
    "    ind = np.array([polygon.contains(Point(x, y)) for x, y in point_cloud_xy])\n",
    "    return ind\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "\n",
    "def geodetic_to_ecef(lat, lon, alt=0.0):\n",
    "    a = 6378137.0\n",
    "    e2 = 6.69437999014e-3\n",
    "    lat_rad = np.radians(lat)\n",
    "    lon_rad = np.radians(lon)\n",
    "    N = a / np.sqrt(1 - e2 * np.sin(lat_rad)**2)\n",
    "    x = (N + alt) * np.cos(lat_rad) * np.cos(lon_rad)\n",
    "    y = (N + alt) * np.cos(lat_rad) * np.sin(lon_rad)\n",
    "    z = (N * (1 - e2) + alt) * np.sin(lat_rad)\n",
    "    return x, y, z\n",
    "\n",
    "# ====== ì„¤ì • ======\n",
    "use_gps_filtering = False  # ğŸš© True: í•„í„°ë§ ì‚¬ìš©, False: ì „ì²´ ì‚¬ìš©\n",
    "\n",
    "target_gps_coords = np.array([\n",
    "    [37.47045, 126.9582],\n",
    "    [37.47051, 126.9593],\n",
    "    [37.47242, 126.9594],\n",
    "    [37.47242, 126.9583]\n",
    "])\n",
    "# ==================\n",
    "\n",
    "target_ecef_coords = np.array([geodetic_to_ecef(lat, lon) for lat, lon in target_gps_coords])\n",
    "transformer = ecef_to_utm_transformer(zone_number=52, zone_letter=\"north\")\n",
    "target_utm_coords = ecef_to_utm_points(target_ecef_coords, transformer)\n",
    "\n",
    "# ====== í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì¤€ë¹„ ======\n",
    "points = np.asarray(pcd.points).astype(np.float64)\n",
    "colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "if use_gps_filtering:\n",
    "    # (1) x, y ì¶”ì¶œ\n",
    "    points_utm = ecef_to_utm_points(points, transformer)\n",
    "    point_xy = points_utm[:, :2]\n",
    "\n",
    "    # (2) ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    inside_ind = filter_points_in_polygon(point_xy, target_utm_coords)\n",
    "\n",
    "    # (3) í•„í„°ë§ ì ìš©\n",
    "    inside_points = points[inside_ind]\n",
    "    inside_colors = colors[inside_ind] if colors is not None else None\n",
    "    inside_normals = normals[inside_ind] if normals is not None else None\n",
    "\n",
    "    print(f\"Filtered point numbers: {len(inside_points)}\")\n",
    "else:\n",
    "    # í•„í„°ë§ ì—†ì´ ì „ì²´ ì‚¬ìš©\n",
    "    inside_points = points\n",
    "    inside_colors = colors\n",
    "    inside_normals = normals\n",
    "    print(f\"No filtering applied. Total points: {len(inside_points)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered hegiht range: 48.9842511492743 ~ 108.69018882876587\n",
      "Filtered point numbers: 9004462\n"
     ]
    }
   ],
   "source": [
    "# 1. Height-based Filetering\n",
    "\n",
    "# ë†’ì´ê°€ 0m ì´ìƒì¸ í¬ì¸íŠ¸ë§Œ í•„í„°ë§\n",
    "filtered_indices = inside_points[:, 2] >= -100.0  # Z ê°’ì´ thr ì´ìƒì¸ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŒ\n",
    "filtered_points = inside_points[filtered_indices]  # Z ê°’ì´ thr ì´ìƒì¸ í¬ì¸íŠ¸ë“¤ë§Œ ì„ íƒ\n",
    "\n",
    "# 3. í†µê³„ì ìœ¼ë¡œ ë†’ì´ ë²”ìœ„ ë²—ì–´ë‚˜ëŠ” ë…¸ì´ì¦ˆ ì œê±°\n",
    "z_values = filtered_points[:, 2]  # Z ê°’ë§Œ ì¶”ì¶œ\n",
    "mean_z = np.mean(z_values)\n",
    "std_z = np.std(z_values)\n",
    "\n",
    "# ì˜ˆì‹œ: í‰ê·  Â± 3 * í‘œì¤€í¸ì°¨ ë²”ìœ„ ë‚´ì˜ í¬ì¸íŠ¸ë“¤ë§Œ ë‚¨ê¹€\n",
    "z_threshold_upper = mean_z + 3 * std_z\n",
    "z_threshold_lower = mean_z - 1.5 * std_z\n",
    "\n",
    "print(f\"Filtered hegiht range: {z_threshold_lower} ~ {z_threshold_upper}\")\n",
    "# ë²”ìœ„ ë°–ì˜ í¬ì¸íŠ¸ ì œê±°\n",
    "final_filtered_indices = (z_values >= z_threshold_lower) & (z_values <= z_threshold_upper)\n",
    "filtered_points = filtered_points[final_filtered_indices]\n",
    "\n",
    "# ìƒ‰ìƒ ë° ë²•ì„  ë²¡í„°ë„ í•„í„°ë§\n",
    "if colors is not None:\n",
    "    filtered_colors = inside_colors[filtered_indices][final_filtered_indices]\n",
    "else:\n",
    "    filtered_colors = None\n",
    "\n",
    "if normals is not None:\n",
    "    filtered_normals = inside_normals[filtered_indices][final_filtered_indices]\n",
    "else:\n",
    "    filtered_normals = None\n",
    "\n",
    "filtered_pcd = o3d.geometry.PointCloud()\n",
    "filtered_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "# ìƒ‰ìƒ ë° ë²•ì„  ë²¡í„°ë„ í•„í„°ë§í•œ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "if filtered_colors is not None:\n",
    "    filtered_pcd.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "if filtered_normals is not None:\n",
    "    filtered_pcd.normals = o3d.utility.Vector3dVector(filtered_normals)\n",
    "    \n",
    "# í•„í„°ë§ëœ í¬ì¸íŠ¸ ìˆ˜ ì¶œë ¥\n",
    "print(f\"Filtered point numbers: {len(filtered_points)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOR Filtered point count: 8179208\n",
      "Point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/filtered/filtered_utm.ply\n"
     ]
    }
   ],
   "source": [
    "# 2. SOR (Statistical Outlier Removal) ë…¸ì´ì¦ˆ ì œê±°\n",
    "nb_neighbors = 20  # ê° í¬ì¸íŠ¸ì— ëŒ€í•´ ê³ ë ¤í•  ì´ì›ƒ í¬ì¸íŠ¸ì˜ ê°œìˆ˜\n",
    "std_ratio = 1.0    # í‘œì¤€í¸ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´ìƒì¹˜ ì œê±° ê¸°ì¤€ (í‘œì¤€í¸ì°¨ ë°°ìˆ˜)\n",
    "\n",
    "\n",
    "# remove_statistical_outlierëŠ” í¬ì¸íŠ¸ ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n",
    "sor_pcd, sor_idx = filtered_pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "print(f\"SOR Filtered point count: {len(sor_pcd.points)}\")\n",
    "\n",
    "# .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "o3d.io.write_point_cloud(output_ply_path, sor_pcd)\n",
    "print(f\"Point cloud saved to: {output_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë˜ í¬ì¸íŠ¸ ìˆ˜: 6942341\n",
      "ë‹¤ìš´ìƒ˜í”Œ í›„: 3561756\n"
     ]
    }
   ],
   "source": [
    "# EXT-3. grid-based downsample\n",
    "import numpy as np\n",
    "\n",
    "def grid_downsample_mean_z_with_attributes(points, colors=None, normals=None, grid_size=0.01):\n",
    "    \"\"\"\n",
    "    í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ê·¸ë¦¬ë“œ ë‹¨ìœ„ë¡œ ë‹¤ìš´ìƒ˜í”Œë§í•˜ê³ , z í‰ê· ìœ¼ë¡œ í•˜ë‚˜ì˜ ì ì„ ë‚¨ê¸´ë‹¤.\n",
    "    colorsì™€ normalsë„ ê°ê° í‰ê· ìœ¼ë¡œ ë³‘í•© (ì„ íƒì‚¬í•­)\n",
    "\n",
    "    Returns:\n",
    "        down_points: (M, 3)\n",
    "        down_colors: (M, 3) or None\n",
    "        down_normals: (M, 3) or None\n",
    "    \"\"\"\n",
    "    xy_indices = np.floor(points[:, :2] / grid_size).astype(np.int32)\n",
    "    keys = [tuple(idx) for idx in xy_indices]\n",
    "\n",
    "    grid_dict = {}\n",
    "    for i, key in enumerate(keys):\n",
    "        if key not in grid_dict:\n",
    "            grid_dict[key] = {\n",
    "                \"z_list\": [],\n",
    "                \"color_list\": [],\n",
    "                \"normal_list\": []\n",
    "            }\n",
    "        grid_dict[key][\"z_list\"].append(points[i, 2])\n",
    "        if colors is not None:\n",
    "            grid_dict[key][\"color_list\"].append(colors[i])\n",
    "        if normals is not None:\n",
    "            grid_dict[key][\"normal_list\"].append(normals[i])\n",
    "\n",
    "    down_points, down_colors, down_normals = [], [], []\n",
    "    for key, val in grid_dict.items():\n",
    "        key = np.array(key, dtype=np.float64)\n",
    "        x_center = (key[0] + 0.5) * grid_size\n",
    "        y_center = (key[1] + 0.5) * grid_size        \n",
    "        z_mean = np.mean(val[\"z_list\"])\n",
    "        down_points.append([x_center, y_center, z_mean])\n",
    "\n",
    "        if colors is not None:\n",
    "            down_colors.append(np.mean(val[\"color_list\"], axis=0))\n",
    "        if normals is not None:\n",
    "            down_normals.append(np.mean(val[\"normal_list\"], axis=0))\n",
    "\n",
    "    return (\n",
    "        np.array(down_points),\n",
    "        np.array(down_colors) if colors is not None else None,\n",
    "        np.array(down_normals) if normals is not None else None\n",
    "    )\n",
    "\n",
    "sor_points = np.asarray(sor_pcd.points).astype(np.float64)\n",
    "sor_colors = filtered_colors[sor_idx]\n",
    "sor_normals = filtered_normals[sor_idx]\n",
    "down_points, down_colors, down_normals = grid_downsample_mean_z_with_attributes(sor_points, sor_colors, sor_normals, grid_size=0.05)\n",
    "\n",
    "# 4. í•„í„°ë§ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ì—…ë°ì´íŠ¸\n",
    "down_pcd = o3d.geometry.PointCloud()\n",
    "down_pcd.points = o3d.utility.Vector3dVector(down_points)\n",
    "\n",
    "# ìƒ‰ìƒ ë° ë²•ì„  ë²¡í„°ë„ í•„í„°ë§í•œ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "if down_colors is not None:\n",
    "    down_pcd.colors = o3d.utility.Vector3dVector(down_colors)\n",
    "\n",
    "if down_normals is not None:\n",
    "    down_pcd.normals = o3d.utility.Vector3dVector(down_normals)\n",
    "\n",
    "output_ply_path = os.path.join(workspace_dir,'nerf_output/exports/pcd/filtered/grid_filtered_utm.ply')\n",
    "\n",
    "# .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "o3d.io.write_point_cloud(output_ply_path, down_pcd)\n",
    "\n",
    "print(\"ì›ë˜ í¬ì¸íŠ¸ ìˆ˜:\", len(sor_points))\n",
    "print(\"ë‹¤ìš´ìƒ˜í”Œ í›„:\", down_points.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[299877.0, 3874302.0, 300300.0, 3874898.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     min_max \u001b[38;5;241m=\u001b[39m (x_min, y_min, x_max, y_max)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m min_max, grid_colors \u001b[38;5;66;03m#(num of grid points, 3)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m min_max_color_phase, grid_colors \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_interpolate_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_pcd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mpatch_interpolate_color\u001b[0;34m(pcd)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m([x_min, y_min, x_max, y_max])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ê·¸ë¦¬ë“œì˜ í•´ìƒë„ ì •ì˜\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m grid_x, grid_y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_max\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_max\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 0.05m ê°„ê²©ì˜ ê·¸ë¦¬ë“œ\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 4. ë³´ê°„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# ê¸°ì¡´ í¬ì¸íŠ¸ì˜ x, y ê°’\u001b[39;00m\n\u001b[1;32m     24\u001b[0m xy_points \u001b[38;5;241m=\u001b[39m points[:, :\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/nerfstudio/lib/python3.8/site-packages/numpy/lib/index_tricks.py:174\u001b[0m, in \u001b[0;36mnd_grid.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    171\u001b[0m     nn \u001b[38;5;241m=\u001b[39m [_nx\u001b[38;5;241m.\u001b[39marange(_x, dtype\u001b[38;5;241m=\u001b[39m_t)\n\u001b[1;32m    172\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m _x, _t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(size, (typ,)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(size))]\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     nn \u001b[38;5;241m=\u001b[39m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, kk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    176\u001b[0m     step \u001b[38;5;241m=\u001b[39m kk\u001b[38;5;241m.\u001b[39mstep\n",
      "File \u001b[0;32m~/.conda/envs/nerfstudio/lib/python3.8/site-packages/numpy/core/numeric.py:1790\u001b[0m, in \u001b[0;36mindices\u001b[0;34m(dimensions, dtype, sparse)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         res \u001b[38;5;241m=\u001b[39m res \u001b[38;5;241m+\u001b[39m (idx,)\n\u001b[1;32m   1789\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1790\u001b[0m         \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. interpolate color\n",
    "import scipy\n",
    "\n",
    "\n",
    "def patch_interpolate_color(pcd):\n",
    "\n",
    "    # 1. í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "\n",
    "    trunc_fun = lambda x: np.round(x) # ex. 1m precision\n",
    "\n",
    "    # 3. í‰ë©´ ìƒì—ì„œ ë³´ê°„í•  ê·¸ë¦¬ë“œ ì •ì˜\n",
    "    x_min, y_min = trunc_fun(np.min(points[:, 0])), trunc_fun(np.min(points[:, 1]))\n",
    "    x_max, y_max = trunc_fun(np.max(points[:, 0])), trunc_fun(np.max(points[:, 1]))\n",
    "    \n",
    "    print([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    # ê·¸ë¦¬ë“œì˜ í•´ìƒë„ ì •ì˜\n",
    "    grid_x, grid_y = np.mgrid[x_min:x_max:0.05, y_min:y_max:0.05]  # 0.05m ê°„ê²©ì˜ ê·¸ë¦¬ë“œ\n",
    "\n",
    "    # 4. ë³´ê°„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "    # ê¸°ì¡´ í¬ì¸íŠ¸ì˜ x, y ê°’\n",
    "    xy_points = points[:, :2]\n",
    "\n",
    "    # 6. Color ë³´ê°„\n",
    "    grid_colors = np.empty((grid_x.shape[0], grid_x.shape[1], 3), dtype=np.float64)\n",
    "    for i in range(3):  # ê° ì±„ë„(RGB)ì— ëŒ€í•´ ë³´ê°„\n",
    "        grid_colors[:, :, i] = scipy.interpolate.griddata(xy_points, colors[:, i], (grid_x, grid_y), method='nearest')\n",
    "    \n",
    "    \n",
    "    min_max = (x_min, y_min, x_max, y_max)\n",
    "    return min_max, grid_colors #(num of grid points, 3)\n",
    "\n",
    "min_max_color_phase, grid_colors = patch_interpolate_color(filtered_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4147475.85 4147551.97 4147429.86 4147419.11 4147479.66 4147416.16\n",
      " 4147493.76 4147413.16 4147520.45 4147401.08]\n",
      "Point cloud with rounded coordinates saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm_floor.ply\n"
     ]
    }
   ],
   "source": [
    "# 4. ì†Œìˆ˜ì  ì•„ë˜ 2ë²ˆì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ -> ê²©ìí™”\n",
    "\n",
    "# PointCloudì˜ ì  ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "points = np.asarray(sor_pcd.points)\n",
    "\n",
    "# ì†Œìˆ˜ì  ì•„ë˜ 2ìë¦¬ê¹Œì§€ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì œê±°\n",
    "rounded_points = np.trunc(points * 100) * 0.01\n",
    "print(rounded_points[:10, 1])\n",
    "# ì†Œìˆ˜ì  ì•„ë˜ 2ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•œ ì ë“¤ì„ ë‹¤ì‹œ PointCloud ê°ì²´ì— ì„¤ì •\n",
    "sor_pcd.points = o3d.utility.Vector3dVector(rounded_points)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm_floor.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, sor_pcd)\n",
    "\n",
    "print(f\"Point cloud with rounded coordinates saved to: {output_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318799.0 4147372.0 318950.0 4147595.0\n",
      "0.0\n",
      "100.0\n",
      "60.0\n",
      "200.0\n",
      "(3020, 4460)\n",
      "(3020, 4460, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13887/607795458.py:52: RuntimeWarning: invalid value encountered in divide\n",
      "  grid_normals /= norm_magnitudes  # ì •ê·œí™”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_interpolate_utm.ply\n"
     ]
    }
   ],
   "source": [
    "# 5. patch_interpolate_z\n",
    "\n",
    "def patch_interpolate_z(pcd, min_max_color_phase, grid_colors, step=0.05):\n",
    "\n",
    "    # 1. í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "    normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "    trunc_fun = lambda x: np.round(x) # ex. 1m precision\n",
    "    # 3. í‰ë©´ ìƒì—ì„œ ë³´ê°„í•  ê·¸ë¦¬ë“œ ì •ì˜\n",
    "    x_min, y_min = trunc_fun(np.min(points[:, 0])), trunc_fun(np.min(points[:, 1]))\n",
    "    x_max, y_max = trunc_fun(np.max(points[:, 0])), trunc_fun(np.max(points[:, 1]))\n",
    "\n",
    "    # ê·¸ë¦¬ë“œì˜ í•´ìƒë„ ì •ì˜\n",
    "    grid_x, grid_y = np.mgrid[x_min:x_max:step, y_min:y_max:step]  # 0.05m ê°„ê²©ì˜ ê·¸ë¦¬ë“œ\n",
    "\n",
    "    # 4. ë³´ê°„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "    # ê¸°ì¡´ í¬ì¸íŠ¸ì˜ x, y ê°’\n",
    "    xy_points = points[:, :2]\n",
    "\n",
    "    # z ê°’ì€ ëª¨ë‘ 0, ì£¼ë³€ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë³´ê°„í•  ì˜ˆì •\n",
    "    z_values = points[:, 2]\n",
    "\n",
    "    # 5. ë³´ê°„: griddata ì‚¬ìš©í•˜ì—¬ ë¹ˆê³µê°„ì„ ì±„ìš°ê¸°\n",
    "    # ë°©ë²•: 'linear', 'cubic', 'nearest' ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ\n",
    "    grid_z = scipy.interpolate.griddata(xy_points, z_values, (grid_x, grid_y), method='nearest')\n",
    "\n",
    "    # 6. Color ë³´ê°„\n",
    "    c_x_min, c_y_min, c_x_max, c_y_max = min_max_color_phase\n",
    "    x_min_ind = int(trunc_fun((x_min - c_x_min)/step))\n",
    "    y_min_ind = int(trunc_fun((y_min - c_y_min)/step))\n",
    "    x_max_ind = grid_colors.shape[0] - int(trunc_fun((c_x_max - x_max)/step))\n",
    "    y_max_ind = grid_colors.shape[1] - int(trunc_fun((c_y_max - y_max)/step))\n",
    "    grid_colors = grid_colors[x_min_ind:x_max_ind, y_min_ind:y_max_ind]\n",
    "    \n",
    "\n",
    "    \n",
    "    # 7. Normal ë³´ê°„\n",
    "    grid_normals = np.empty((grid_x.shape[0], grid_x.shape[1], 3), dtype=np.float64)\n",
    "    for i in range(3):  # ê° ë…¸ë©€ ë²¡í„° ì„±ë¶„ì— ëŒ€í•´ ë³´ê°„\n",
    "        grid_normals[:, :, i] = scipy.interpolate.griddata(xy_points, normals[:, i], (grid_x, grid_y), method='nearest')\n",
    "\n",
    "    # ë³´ê°„ í›„, ë…¸ë©€ ë²¡í„°ë¥¼ ë‹¨ìœ„ ë²¡í„°ë¡œ ì •ê·œí™”\n",
    "    norm_magnitudes = np.linalg.norm(grid_normals, axis=2, keepdims=True)\n",
    "    grid_normals /= norm_magnitudes  # ì •ê·œí™”\n",
    "\n",
    "    # 8. ë³´ê°„ëœ ê²°ê³¼ë¥¼ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ë³€í™˜\n",
    "    interpolated_points = np.vstack((grid_x.flatten(), grid_y.flatten(), grid_z.flatten())).T\n",
    "    interpolated_colors = grid_colors.reshape(-1, 3)\n",
    "    interpolated_normals = grid_normals.reshape(-1, 3)\n",
    "\n",
    "    # 9. Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´ë¡œ ë³€í™˜\n",
    "    interpolated_pcd = o3d.geometry.PointCloud()\n",
    "    interpolated_pcd.points = o3d.utility.Vector3dVector(interpolated_points)\n",
    "    interpolated_pcd.colors = o3d.utility.Vector3dVector(interpolated_colors)\n",
    "    interpolated_pcd.normals = o3d.utility.Vector3dVector(interpolated_normals)\n",
    "\n",
    "    return interpolated_pcd\n",
    "\n",
    "interpolated_pcd = patch_interpolate_z(sor_pcd, min_max_color_phase, grid_colors)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_interpolate_utm.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, interpolated_pcd)\n",
    "\n",
    "print(f\"Point cloud saved to: {output_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Patch-based Plane Interpolation\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ X, Y ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•œ í•¨ìˆ˜\n",
    "def split_point_cloud(pcd, x_step=1.0, y_step=1.0):\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "    normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "    x_min, y_min = np.min(points[:, 0]), np.min(points[:, 1])\n",
    "    x_max, y_max = np.max(points[:, 0]), np.max(points[:, 1])\n",
    "\n",
    "    # X, Y ë²”ìœ„ì— ë§ê²Œ ê·¸ë¦¬ë“œ ì •ì˜\n",
    "    x_range = np.arange(x_min, x_max, x_step)\n",
    "    y_range = np.arange(y_min, y_max, y_step)\n",
    "\n",
    "    # ê·¸ë¦¬ë“œ ìƒì— í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ë¶„í• \n",
    "    sub_clouds = []\n",
    "    for x_start in x_range:\n",
    "        for y_start in y_range:\n",
    "            # í˜„ì¬ ê·¸ë¦¬ë“œì— í•´ë‹¹í•˜ëŠ” ì ë“¤ì„ í•„í„°ë§\n",
    "            mask = (points[:, 0] >= x_start) & (points[:, 0] < x_start + x_step) & \\\n",
    "                   (points[:, 1] >= y_start) & (points[:, 1] < y_start + y_step)\n",
    "\n",
    "            sub_points = points[mask]            \n",
    "            sub_colors = colors[mask]\n",
    "            sub_normals = normals[mask]\n",
    "\n",
    "            if len(sub_points) > 0:  # í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°\n",
    "                sub_pcd = o3d.geometry.PointCloud()\n",
    "                sub_pcd.points = o3d.utility.Vector3dVector(sub_points)\n",
    "                sub_pcd.colors = o3d.utility.Vector3dVector(sub_colors)\n",
    "                sub_pcd.normals = o3d.utility.Vector3dVector(sub_normals)\n",
    "                sub_clouds.append(sub_pcd)\n",
    "\n",
    "    return sub_clouds\n",
    "\n",
    "\n",
    "\n",
    "# ì˜ˆì‹œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ (sor_pcdëŠ” ì´ë¯¸ ì •ë¦¬ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ)\n",
    "\n",
    "input_ply_path = '/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply'\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "\n",
    "# í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ x, y ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "splited_sub_clouds = split_point_cloud(pcd, x_step=5, y_step=5)  # ì›í•˜ëŠ” í¬ê¸°ë§Œí¼ ì˜ë¼ì„œ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94030/910921686.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  grid_normals /= norm_magnitudes  # ì •ê·œí™”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plane ì¶”ì¶œ\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "\n",
    "def sub_pointcloud_interpolation(sub_clouds, inlier_thr = 0.8):\n",
    "    cnt = 0\n",
    "    max_ratio = 0.0\n",
    "    interpolated_sub_clouds = []\n",
    "    for pcd in sub_clouds:\n",
    "        if(len(pcd.points) <3):\n",
    "            # print(\"too small pcd\")\n",
    "            continue\n",
    "        plane_model, inliers = pcd.segment_plane(distance_threshold=0.10,\n",
    "                                                ransac_n=3,\n",
    "                                                num_iterations=1000)\n",
    "        [a, b, c, d] = plane_model\n",
    "        # print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "        \n",
    "        total = len(pcd.points)\n",
    "        inlier_ratio = len(inliers)/ total\n",
    "        if(max_ratio < inlier_ratio):\n",
    "            max_ratio = inlier_ratio\n",
    "\n",
    "        if(inlier_ratio >= inlier_thr):\n",
    "            cnt += 1        \n",
    "            inlier_pcd = pcd.select_by_index(inliers)\n",
    "            interpolated_pcd = patch_interpolate(inlier_pcd)\n",
    "            interpolated_sub_clouds.append(interpolated_pcd)\n",
    "\n",
    "    print(cnt)\n",
    "    print(max_ratio)\n",
    "    points = np.empty((0, 3))\n",
    "    colors = np.empty((0, 3))\n",
    "    normals = np.empty((0, 3))\n",
    "    for sub_pcd in interpolated_sub_clouds:\n",
    "        points = np.vstack((points, sub_pcd.points))\n",
    "        colors = np.vstack((colors, sub_pcd.colors))\n",
    "        normals = np.vstack((normals, sub_pcd.normals))\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "    return pcd\n",
    "\n",
    "# .ply íŒŒì¼ë¡œ ì €ì¥\n",
    "inlier_thr = 0.4\n",
    "pcd = sub_pointcloud_interpolation(splited_sub_clouds, inlier_thr)\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/test/test.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Loaded 5757153 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] /root/Open3D/build/poisson/src/ext_poisson/PoissonRecon/Src/FEMTree.IsoSurface.specialized.inl (Line 1858)\n",
      "          Extract\n",
      "          bad average roots: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "pcd, depth=9)\n",
    "\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/test/test.ply\"\n",
    "o3d.io.write_triangle_mesh(output_ply_path, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5757153 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "input_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "print(f\"Loaded {len(pcd.points)} points from {input_ply_path}\")\n",
    "\n",
    "pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/test/test.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7724974 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECEF to UTM\n",
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "def utm_to_ecef_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for UTM to ECEF conversion.\"\"\"\n",
    "    return Transformer.from_crs(f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\", \"EPSG:4978\")\n",
    "\n",
    "def utm_to_ecef_points(points_utm: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts UTM points to ECEF coordinates.\n",
    "    \n",
    "    points_utm : (N, 3) - UTM coordinates (E, N, Altitude)\n",
    "    \"\"\"\n",
    "    \n",
    "    e, n, alt = points_utm[:, 0], points_utm[:, 1], points_utm[:, 2]\n",
    "    x, y, z = transformer.transform(e, n, alt)\n",
    "    points_ecef = np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    return np.array(points_ecef)\n",
    "\n",
    "input_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\"\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_ecef.ply\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "coords_utm = np.asarray(pcd.points)\n",
    "print(f\"Loaded {len(coords_utm)} points from {input_ply_path}\")\n",
    "\n",
    "# Convert ECEF to UTM\n",
    "transformer = utm_to_ecef_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_ecef = utm_to_ecef_points(coords_utm, transformer)\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(coords_ecef)\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3047504.68074928  4051184.25442885  3857815.59610601]\n",
      " [-3047507.34951665  4051186.55475769  3857811.00875926]\n",
      " [-3047511.06631932  4051183.40606937  3857811.55604814]\n",
      " [-3047508.20908455  4051180.82131159  3857816.5130461 ]]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "def utm_to_ecef_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for UTM to ECEF conversion.\"\"\"\n",
    "    return Transformer.from_crs(f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\", \"EPSG:4978\")\n",
    "\n",
    "def utm_to_ecef_points(points_utm: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts UTM points to ECEF coordinates.\n",
    "    \n",
    "    points_utm : (N, 3) - UTM coordinates (E, N, Altitude)\n",
    "    \"\"\"\n",
    "    \n",
    "    e, n, alt = points_utm[:, 0], points_utm[:, 1], points_utm[:, 2]\n",
    "    x, y, z = transformer.transform(e, n, alt)\n",
    "    points_ecef = np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    return np.array(points_ecef)\n",
    "\n",
    "coords_utm_y1 = np.array([    \n",
    "    [318890.442133, 4147487.223265, 140.161864],\n",
    "        [318890.909859, 4147481.202181, 140.201193],\n",
    "        [318895.667564, 4147481.597686, 140.240356], \n",
    "        [318895.201717, 4147487.595746, 140.205322],    \n",
    "    ], dtype=np.float64)\n",
    "\n",
    "coords_utm_j1 = np.array([    \n",
    "    [318890.849485, 4147481.063982, 140.179913],\n",
    "        [318891.481113, 4147475.233882, 140.122883],\n",
    "        [318896.339060, 4147475.711492, 140.231966], \n",
    "        [318895.749198, 4147481.881790, 140.243442],    \n",
    "    ], dtype=np.float64)\n",
    "\n",
    "transformer = utm_to_ecef_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_ecef_y1 = utm_to_ecef_points(coords_utm_y1, transformer)\n",
    "coords_ecef_j1 = utm_to_ecef_points(coords_utm_j1, transformer)\n",
    "print(coords_ecef_j1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[[ 318892.84107189 4147481.48802571]\n",
      " [ 318891.41463701 4147475.39550037]\n",
      " [ 318893.65244937 4147477.57361983]\n",
      " [ 318896.17264202 4147475.72848789]]\n",
      "\n",
      "[[ 318895.16213698 4147487.63786774]\n",
      " [ 318890.30214663 4147487.14235971]\n",
      " [ 318892.67867724 4147484.74360234]\n",
      " [ 318892.82241112 4147481.75383504]]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for ECEF to UTM conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to UTM coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    points_utm = np.stack([e, n, alt], axis = -1) \n",
    "    \n",
    "    return np.array(points_utm)\n",
    "\n",
    "trans_cloudcompare = np.array([3047000.00, -4051000.00, -3857000.00], dtype = np.float64)\n",
    "\n",
    "\n",
    "coords_ecef_j1 = np.array(\n",
    "    [\n",
    "        [-506.078119, 182.807889, 816.023397],\n",
    "        [-507.263343, 186.535461, 811.139028],         \n",
    "        [-508.224556, 184.170274, 812.938215], # ì†Œì˜ ã…—\n",
    "        [-510.949760, 183.534916, 811.549471],\n",
    "        ]\n",
    ") \n",
    "\n",
    "coords_ecef_j1 -= trans_cloudcompare\n",
    "\n",
    "coords_ecef_y1 = np.array(\n",
    "        [[-505.581044, 178.509305, 820.971791],\n",
    "        [-501.903964, 181.685998, 820.466010],\n",
    "        [-504.697447, 181.360312, 818.597099],\n",
    "        [-505.958553, 182.689592, 816.230171]]\n",
    "    )    \n",
    "\n",
    "coords_ecef_y1 -= trans_cloudcompare\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "# Convert ECEF to UTM\n",
    "transformer = ecef_to_utm_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_utm_j1 = ecef_to_utm_points(coords_ecef_j1, transformer)\n",
    "coords_utm_y1 = ecef_to_utm_points(coords_ecef_y1, transformer)\n",
    "print(coords_utm_j1[:, :2])\n",
    "print(\"\")\n",
    "print(coords_utm_y1[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 188 points from /workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/model_based_tracking.ply\n",
      "188\n",
      "Predicted points saved to /workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/GT.npy\n",
      "Predicted points saved to /workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/pred_points_uav.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Final evaluation(ATE)\n",
    "trans_cloudcompare = np.array([3047000.00, -4051000.00, -3857000.00], dtype = np.float64)\n",
    "GT_feature_vertices = np.array([\n",
    "        [-501.967988, 181.675080, 820.428803],\n",
    "        [-507.307352, 186.436744, 811.205693],\n",
    "        [-510.972234, 183.477112, 811.603174],\n",
    "        [-505.591991, 178.600039, 820.896150]\n",
    "    ])\n",
    "\n",
    "GT_feature_vertices -= trans_cloudcompare\n",
    "    \n",
    "    \n",
    "    \n",
    "# .ply íŒŒì¼ ì½ê¸°        \n",
    "input_ply_path = \"/workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/model_based_tracking.ply\"\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "print(f\"Loaded {len(pcd.points)} points from {input_ply_path}\")\n",
    "\n",
    "pred_points = np.asarray(pcd.points)  \n",
    "print(len(pred_points))\n",
    "\n",
    "\n",
    "GT_feature_vertices = ecef_to_utm_points(GT_feature_vertices, transformer)\n",
    "pred_points = ecef_to_utm_points(pred_points, transformer)\n",
    "\n",
    "GT_points_filename = \"/workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/GT.npy\"\n",
    "np.save(GT_points_filename, GT_feature_vertices)\n",
    "print(f\"Predicted points saved to {GT_points_filename}\")\n",
    "\n",
    "pred_points_filename = \"/workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/pred_points_uav.npy\"\n",
    "np.save(pred_points_filename, pred_points)\n",
    "print(f\"Predicted points saved to {pred_points_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCD centering with translation.json\n",
    "\n",
    "import open3d as o3d\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. PCD íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "pcd = o3d.io.read_point_cloud(\"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/pcd/filtered/filtered_ck.ply\")  # 'input.pcd'ëŠ” ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "# 2. JSON íŒŒì¼ì—ì„œ translation ê°’ ì½ê¸°\n",
    "with open(\"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/translation_ck.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "translation_data = json_data[\"global_translation\"]\n",
    "\n",
    "# 3. x, y, z ì¶”ì¶œ\n",
    "\n",
    "\n",
    "# 4. í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— translation ì ìš©\n",
    "translation_vector = - np.array(translation_data)\n",
    "pcd.translate(translation_vector)\n",
    "\n",
    "# 5. ê²°ê³¼ ì €ì¥\n",
    "o3d.io.write_point_cloud(\"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/pcd/filtered/centered_filtered_ck.pcd\", pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
