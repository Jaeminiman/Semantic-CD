{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLMAP-NeRFStudio 간 좌표계 변환 실험 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# choice: Every transforms can be written as function or transformation matrix\n",
    "T_opengl2opencv = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "T_colmap2nerf = np.array([[1, 0, 0, 0], [0, 0, 1, 0], [0, -1, 0, 0], [0, 0, 0, 1]]) # applied_transform\n",
    "\n",
    "# convert between opencv and nerfstudio function version\n",
    "def colmap_to_nerfstudio(c2w):\n",
    "    # c2w: expected shape (4, 4)\n",
    "    c2w[..., 0:3, 1:3] *= -1 # flip the y_c, z_c axis (2D OPENCV -> OPENGL)\n",
    "\n",
    "    c2w = c2w[..., np.array([0, 2, 1, 3]), :] # exchange y, z (COLMAP -> NeRFStudio)\n",
    "    c2w[..., 2, :] *= -1 # flip z axis (COLMAP -> NeRFStudio)\n",
    "    return c2w\n",
    "\n",
    "# convert between opencv and nerfstudio matrix version\n",
    "def colmap_to_nerfstudio_matrix_ver(c2w):\n",
    "    # c2w: expected shape (4, 4)\n",
    "\n",
    "    T_opencv2colmap = c2w\n",
    "    T_colmap_opencv = T_opencv2colmap\n",
    "    \n",
    "    T_opencv_opengl = T_opengl2opencv\n",
    "    T_nerf_colmap = T_colmap2nerf    \n",
    "\n",
    "    T_nerf_opengl = T_nerf_colmap @ T_colmap_opencv @ T_opencv_opengl\n",
    "    T_opengl2nerf = T_nerf_opengl \n",
    "    c2w = T_opengl2nerf\n",
    "    return c2w\n",
    "\n",
    "# convert between opencv and opengl function version\n",
    "def opengl_to_opencv(c2w):\n",
    "    transform = np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]])\n",
    "    if isinstance(c2w, torch.Tensor):\n",
    "        transform = torch.Tensor(transform).to(c2w)\n",
    "    c2w[..., :3, :3] @= transform\n",
    "    return c2w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# [Test] coordinate transform (COLMAP -> NeRFStudio) evaluation\n",
    "q_colmap2opencv = np.array([0.995759,0.000310773,0.0178788,-0.0902497]) \n",
    "t_colmap2opencv = np.array([4.34879,-1.51327,-0.0316503])\n",
    "T_colmap2opencv = quaternion_to_transform_matrix(q_colmap2opencv, t_colmap2opencv) # T_cw\n",
    "T_opencv2colmap = np.linalg.inv(T_colmap2opencv) # c2w\n",
    "T_opengl2nerf = colmap_to_nerfstudio(T_opencv2colmap.copy())\n",
    "\n",
    "# test 1\n",
    "T_nerf_opengl = T_opengl2nerf\n",
    "T_opengl_opencv = np.linalg.inv(T_opengl2opencv)\n",
    "T_colmap_nerf = np.linalg.inv(T_colmap2nerf)\n",
    "T_colmap_opencv_pred = T_colmap_nerf@T_nerf_opengl@T_opengl_opencv\n",
    "T_opencv2colmap_pred = T_colmap_opencv_pred\n",
    "print(np.allclose(T_opencv2colmap, T_opencv2colmap_pred, atol=1e-5))\n",
    "\n",
    "# test 2\n",
    "T_opengl2nerf_pred = colmap_to_nerfstudio_matrix_ver(T_opencv2colmap.copy())\n",
    "\n",
    "print(np.allclose(T_opengl2nerf, T_opengl2nerf_pred, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Render] Transform cameras from transforms.json to camera_path.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale: 0.1889979446048152\n",
      "Transformation applied and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write Camera_path(opengl-NeRF to opengl-webgui)\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from R3DR.utils import dir_utils\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "# 파일 경로\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2\"\n",
    "nerfstudio_transforms_path = os.path.join(workspace_dir, \"new_correspondence/ns_processed/transforms.json\")\n",
    "webgui_camera_path = os.path.join(workspace_dir, \"new_correspondence/ns_processed/camera_path.json\")\n",
    "config_path = os.path.join(workspace_dir, \"new_correspondence/config/config.yaml\")\n",
    "fov = 40\n",
    "\n",
    "config = dir_utils.load_config(config_path)\n",
    "dir_utils.validate_config(config)\n",
    "\n",
    "# dataparser_transforms.json 읽기\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser = json.load(file)\n",
    "\n",
    "# 변환 행렬과 스케일 가져오기(ok)\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser['scale']\n",
    "print(f\"scale: {scale}\")\n",
    "\n",
    "# transforms.json 읽기\n",
    "with open(nerfstudio_transforms_path, 'r') as file:\n",
    "    transforms = json.load(file) # c2w\n",
    "\n",
    "T_nerf_colmap = homogeneous(np.array(transforms['applied_transform'])) # (4, 4), applied_transform(T_nerf_colmap)\n",
    "T_webgui_nerf =  T_webgui_colmap @ np.linalg.inv(T_nerf_colmap) # (4, 4) orient_pose_transform(T_webgui_nerf)\n",
    "\n",
    "# 모든 프레임에 대해 변환 적용\n",
    "for frame in transforms['frames']:\n",
    "\n",
    "    T_nerf_opengl = np.array(frame['transform_matrix']) # (4, 4)\n",
    "    \n",
    "\n",
    "    # 변환 행렬 적용\n",
    "    T_webgui_opengl = T_webgui_nerf @ T_nerf_opengl     \n",
    "    T_webgui_opengl[:3, 3] *= scale\n",
    "    frame['transform_matrix'] = T_webgui_opengl.flatten().tolist()\n",
    "    \n",
    "\n",
    "sorted_frames = sorted(transforms['frames'], key=lambda frame: frame['file_path'])\n",
    "\n",
    "downscale_factor = int(config['nerf_settings']['ns_train_options']['dataparser_options']['downscale-factor'])\n",
    "\n",
    "w, h = [int(v / downscale_factor) for v in (sorted_frames[0]['w'], sorted_frames[0]['h'])]\n",
    "out = {\n",
    "        'camera_type': 'perspective',\n",
    "        'render_height': h,\n",
    "        'render_width': w,\n",
    "        'seconds': len(sorted_frames),\n",
    "        'camera_path': [\n",
    "                {'camera_to_world': frame['transform_matrix'], 'fov': fov, 'aspect': 1, 'file_path': frame['file_path']} for frame in sorted_frames\n",
    "            ]\n",
    "        }\n",
    "# 변경된 내용을 transforms.json 파일에 다시 저장\n",
    "with open(webgui_camera_path, 'w') as file:\n",
    "    json.dump(out, file, indent=4)\n",
    "print(\"Transformation applied and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation applied and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write camera_path(Opencv to ECEF)\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from plyfile import PlyData, PlyElement\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "import time\n",
    "\n",
    "T_opencv_opengl = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "# 파일 경로\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "ecef_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\"\n",
    "webgui_camera_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/ns_processed/camera_path.json\"\n",
    "\n",
    "output_ecef_camera_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/ns_processed/ecef_camera_path.json\"\n",
    "\n",
    "# dataparser_transforms.json 읽기\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "print(scale)\n",
    "\n",
    "# Sim(3) 변환 행렬 생성\n",
    "# NeRFStudio Sim3 정의 상, R, t 먼저 적용 후 전체 scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "\n",
    "# ecef_transforms.json 읽기\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) 변환 행렬 생성 (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "\n",
    "# camera_path.json 읽기\n",
    "with open(webgui_camera_path, 'r') as file:\n",
    "    camera_path_json = json.load(file)\n",
    "\n",
    "out = {\"frames\": []}\n",
    "for camera in camera_path_json['camera_path']:\n",
    "    T_webgui_opengl = np.array(camera['camera_to_world']).reshape(4, 4)\n",
    "    file_path = camera['file_path']\n",
    "\n",
    "    T_ecef_opencv = T_ecef_webgui_sim3 @ T_webgui_opengl @ np.linalg.inv(T_opencv_opengl)    \n",
    "\n",
    "    # retain orthonormal property of rotation\n",
    "    R_wc = T_ecef_opencv[:3, :3] \n",
    "    U, _, V_t = np.linalg.svd(R_wc)\n",
    "    R_wc_norm = U @ V_t\n",
    "    T_ecef_opencv[:3, :3] = R_wc_norm\n",
    "\n",
    "    out[\"frames\"].append({'file_path': file_path, 'camera_to_world': T_ecef_opencv.tolist()})\n",
    "\n",
    "# 변경된 내용을 transforms.json 파일에 저장\n",
    "with open(output_ecef_camera_path, 'w') as file:\n",
    "    json.dump(out, file, indent=4)\n",
    "print(\"Transformation applied and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Geo-registration] Transform pcd/mesh from NeRFStudio to ECEF/UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataparser_transform in 0.00 seconds\n",
      "Loaded ECEF transform in 0.00 seconds\n",
      "Loaded PLY data in 2.01 seconds\n",
      "Converted to ECEF in 0.17 seconds\n",
      "Converted to UTM in 3.07 seconds\n",
      "Converted to central korea in 6.07 seconds\n",
      "ECEF Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_ecef.ply\n",
      "UTM Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_utm.ply\n",
      "중부원점 (EPSG:5186) Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_ck.pcd\n"
     ]
    }
   ],
   "source": [
    "# NeRFStudio(WebGUI) pcd -> ECEF/UTM Geo-registered pcd\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "import time\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def normalize_coordinates(coords):\n",
    "    \"\"\"\n",
    "    좌표 배열에서 각 축의 평균을 계산한 후, 이를 원래 좌표에서 뺀 값을 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        coords (numpy.ndarray): (n, 3) 형태의 좌표 배열.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: 평균이 제거된 (n, 3) 형태의 좌표 배열.\n",
    "    \"\"\"\n",
    "    mean_coords = np.mean(coords, axis=0)  # 각 축(x, y, z)의 평균 계산\n",
    "    normalized_coords = coords - mean_coords  # 평균을 빼서 원점 기준 정규화\n",
    "    return normalized_coords, mean_coords\n",
    "    \n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for ECEF to UTM conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to UTM coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    points_utm = np.stack([e, n, alt], axis = -1) \n",
    "    \n",
    "    return np.array(points_utm)\n",
    "\n",
    "def ecef_to_central_korea_transformer():\n",
    "    \"\"\"Creates a Transformer for ECEF to EPSG:5186 (중부원점) conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", \"EPSG:5186\", always_xy=True)\n",
    "\n",
    "def ecef_to_central_korea_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to 중부원점 (EPSG:5186) coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "    \n",
    "##############################################################################################################################################\n",
    "# User Input\n",
    "##############################################################################################################################################\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial\"\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "##############################################################################################################################################\n",
    "ecef_transforms_path = os.path.join(workspace_dir, \"ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\")\n",
    "\n",
    "ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/point_cloud.ply\")\n",
    "\n",
    "output_dir = os.path.join(workspace_dir, \"nerf_output/exports/pcd/original\")\n",
    "\n",
    "# 디렉토리 생성 (존재하지 않으면)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ECEF Geo-registered PLY 저장 경로\n",
    "output_ecef_ply_path = os.path.join(output_dir, \"point_cloud_ecef.ply\")\n",
    "\n",
    "# UTM Geo-registered PLY 저장 경로\n",
    "output_utm_ply_path = os.path.join(output_dir, \"point_cloud_utm.ply\")\n",
    "\n",
    "# CK Geo-registered PLY 저장 경로\n",
    "output_ck_ply_path = os.path.join(output_dir, \"point_cloud_ck.ply\")\n",
    "\n",
    "# output_ck_translation_path = os.path.join(workspace_dir, \"translation_ck.json\")\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# dataparser_transforms.json 읽기\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "\n",
    "\n",
    "# Sim(3) 변환 행렬 생성\n",
    "# NeRFStudio Sim3 정의 상, R, t 먼저 적용 후 전체 scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "print(f\"Loaded dataparser_transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ecef_transforms.json 읽기\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) 변환 행렬 생성 (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "\n",
    "print(f\"Loaded ECEF transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# .ply 파일 읽기\n",
    "pcd = o3d.io.read_point_cloud(ply_path)\n",
    "points = np.asarray(pcd.points)  # 포인트 데이터 가져오기\n",
    "colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "print(f\"Loaded PLY data in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "# ECEF 변환\n",
    "coords = np.hstack([points, np.ones((points.shape[0], 1))])  # (N, 4)\n",
    "assert(coords.dtype == np.float64)\n",
    "\n",
    "coords_ecef = (T_ecef_webgui_sim3[:3, :] @ coords.T).T  # ECEF 변환 좌표 (x', y', z')\n",
    "\n",
    "print(f\"Converted to ECEF in {time.time() - start_time:.2f} seconds\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert ECEF to UTM\n",
    "transformer = ecef_to_utm_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_utm = ecef_to_utm_points(coords_ecef, transformer)\n",
    "\n",
    "print(f\"Converted to UTM in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 중부원점 변환\n",
    "transformer_central_korea = ecef_to_central_korea_transformer()\n",
    "coords_ck = ecef_to_central_korea_points(coords_ecef, transformer_central_korea)\n",
    "print(f\"Converted to central korea in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# ECEF PCD 객체 생성\n",
    "ecef_pcd = o3d.geometry.PointCloud()\n",
    "ecef_pcd.points = o3d.utility.Vector3dVector(coords_ecef)  # ECEF 좌표 (x, y, z)\n",
    "if colors is not None:\n",
    "    ecef_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "if normals is not None:\n",
    "    ecef_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# UTM PCD 객체 생성\n",
    "utm_pcd = o3d.geometry.PointCloud()\n",
    "utm_pcd.points = o3d.utility.Vector3dVector(coords_utm)  # UTM 좌표 (x, y, z)\n",
    "if colors is not None:\n",
    "    utm_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "if normals is not None:\n",
    "    utm_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# 중부원점 PCD 객체 생성\n",
    "# coords_ck, ck_global_translation = normalize_coordinates(coords_ck)\n",
    "\n",
    "ck_pcd = o3d.geometry.PointCloud()\n",
    "ck_pcd.points = o3d.utility.Vector3dVector(coords_ck)\n",
    "if colors is not None:\n",
    "    ck_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "if normals is not None:\n",
    "    ck_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "# mean_dict = {\"global_translation\": ck_global_translation.tolist()}\n",
    "\n",
    "# with open(output_ck_translation_path, \"w\") as f:\n",
    "#     json.dump(mean_dict, f, indent=4)  # JSON 파일로 저장 (들여쓰기 포함)\n",
    "\n",
    "# ECEF .ply 파일로 저장\n",
    "o3d.io.write_point_cloud(output_ecef_ply_path, ecef_pcd)\n",
    "print(f\"ECEF Transformed point cloud saved to: {output_ecef_ply_path}\")\n",
    "\n",
    "# UTM .ply 파일로 저장\n",
    "o3d.io.write_point_cloud(output_utm_ply_path, utm_pcd)\n",
    "print(f\"UTM Transformed point cloud saved to: {output_utm_ply_path}\")\n",
    "\n",
    "# 중부원점 PLY 저장\n",
    "o3d.io.write_point_cloud(output_ck_ply_path, ck_pcd)\n",
    "print(f\"중부원점 (EPSG:5186) Transformed point cloud saved to: {output_ck_ply_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ECEF transform in 0.00 seconds\n",
      "Loaded PLY data in 1.71 seconds\n",
      "Converted to UTM in 2.94 seconds\n",
      "Converted to central korea in 2.62 seconds\n",
      "Converted to NeRFStudio(WebGUI) in 0.03 seconds\n",
      "중부원점 (EPSG:5186) Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/filtered/filtered_ck.pcd\n",
      "webgui Transformed point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/filtered/filtered_webgui.pcd\n"
     ]
    }
   ],
   "source": [
    "# UTM Geo-registered pcd(Filtered PCD) -> NeRFStudio(WebGUI) pcd(For mesh generation and filtered central pcd)\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer, CRS\n",
    "import time\n",
    "import open3d as o3d\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "def normalize_coordinates(coords):\n",
    "    \"\"\"\n",
    "    좌표 배열에서 각 축의 평균을 계산한 후, 이를 원래 좌표에서 뺀 값을 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        coords (numpy.ndarray): (n, 3) 형태의 좌표 배열.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: 평균이 제거된 (n, 3) 형태의 좌표 배열.\n",
    "    \"\"\"\n",
    "    mean_coords = np.mean(coords, axis=0)  # 각 축(x, y, z)의 평균 계산\n",
    "    normalized_coords = coords - mean_coords  # 평균을 빼서 원점 기준 정규화\n",
    "    return normalized_coords, mean_coords\n",
    "\n",
    "def ecef_to_central_korea_transformer():\n",
    "    \"\"\"Creates a Transformer for ECEF to EPSG:5186 (중부원점) conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", \"EPSG:5186\", always_xy=True)\n",
    "\n",
    "def ecef_to_central_korea_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to 중부원점 (EPSG:5186) coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "\n",
    "def utm_to_ecef_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for UTM to ECEF conversion.\"\"\"\n",
    "    south = \" +south\" if zone_letter == \"S\" else \"\"  # 남반구 설정\n",
    "    utm_crs = CRS.from_proj4(f\"+proj=utm +zone={zone_number}{south} +datum=WGS84 +units=m +no_defs\")\n",
    "    \n",
    "    transformer_utm_to_ecef = Transformer.from_crs(utm_crs, \"EPSG:4978\", always_xy=True)\n",
    "    return transformer_utm_to_ecef  # 올바르게 변환기를 반환\n",
    "\n",
    "def utm_to_ecef_points(points_utm: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UTM (easting, northing, altitude) 좌표를 ECEF 좌표로 변환합니다.\n",
    "    \n",
    "    points_utm : (N, 3)\n",
    "    transformer : UTM->ECEF 변환을 위한 pyproj Transformer\n",
    "    \"\"\"\n",
    "    # UTM 좌표: (easting, northing, altitude)\n",
    "    east, north, alt = points_utm[:, 0], points_utm[:, 1], points_utm[:, 2]\n",
    "    # Transformer.transform의 입력 순서는 (x, y, z) 즉, (east, north, alt)\n",
    "    x, y, z = transformer.transform(east, north, alt)\n",
    "    points_ecef = np.stack([x, y, z], axis=-1)\n",
    "    return points_ecef\n",
    "\n",
    "##############################################################################################################################################\n",
    "# User Input\n",
    "##############################################################################################################################################\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial\"\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/ns_processed/nerfacto/2025-05-30_071924/dataparser_transforms.json\"\n",
    "##############################################################################################################################################\n",
    "ecef_transforms_path = os.path.join(workspace_dir, \"ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\")\n",
    "\n",
    "utm_ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/filtered_utm.ply\")\n",
    "\n",
    "output_webgui_ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/filtered_webgui.pcd\")\n",
    "\n",
    "output_ck_ply_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/filtered_ck.pcd\")\n",
    "output_ck_translation_path = os.path.join(workspace_dir, \"nerf_output/exports/pcd/filtered/translation_ck.json\")\n",
    "\n",
    "# dataparser_transforms.json 읽기\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "\n",
    "\n",
    "# Sim(3) 변환 행렬 생성\n",
    "# NeRFStudio Sim3 정의 상, R, t 먼저 적용 후 전체 scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ecef_transforms.json 읽기\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) 변환 행렬 생성 (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "T_webgui_ecef_sim3 = np.linalg.inv(T_ecef_webgui_sim3)\n",
    "\n",
    "print(f\"Loaded ECEF transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# .ply 파일 읽기\n",
    "pcd = o3d.io.read_point_cloud(utm_ply_path)\n",
    "coords_utm = np.asarray(pcd.points)  # 포인트 데이터 가져오기\n",
    "assert(coords_utm.dtype == np.float64)\n",
    "colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "print(f\"Loaded PLY data in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert UTM to ECEF\n",
    "transformer = utm_to_ecef_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_ecef = utm_to_ecef_points(coords_utm, transformer)\n",
    "coords_ecef = np.hstack([coords_ecef, np.ones((coords_ecef.shape[0], 1))])  # (N, 4)\n",
    "print(f\"Converted to UTM in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 중부원점 변환\n",
    "start_time = time.time()\n",
    "transformer_central_korea = ecef_to_central_korea_transformer()\n",
    "coords_ck = ecef_to_central_korea_points(coords_ecef, transformer_central_korea)\n",
    "print(f\"Converted to central korea in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert ECEF to WebGUI\n",
    "coords_webgui = (T_webgui_ecef_sim3[:3, :] @ coords_ecef.T).T\n",
    "\n",
    "print(f\"Converted to NeRFStudio(WebGUI) in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# WebGUI PCD 객체 생성\n",
    "webgui_pcd = o3d.geometry.PointCloud()\n",
    "webgui_pcd.points = o3d.utility.Vector3dVector(coords_webgui)  # ECEF 좌표 (x, y, z)\n",
    "if colors is not None:\n",
    "    webgui_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "if normals is not None:\n",
    "    webgui_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# 중부원점 PCD 객체 생성\n",
    "ck_pcd = o3d.geometry.PointCloud()\n",
    "coords_ck, ck_global_translation = normalize_coordinates(coords_ck)\n",
    "ck_pcd.points = o3d.utility.Vector3dVector(coords_ck)\n",
    "if colors is not None:\n",
    "    ck_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "if normals is not None:\n",
    "    ck_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "\n",
    "# 중부원점 PLY 저장\n",
    "o3d.io.write_point_cloud(output_ck_ply_path, ck_pcd)\n",
    "print(f\"중부원점 (EPSG:5186) Transformed point cloud saved to: {output_ck_ply_path}\")\n",
    "\n",
    "mean_dict = {\"global_translation\": ck_global_translation.tolist()}\n",
    "\n",
    "with open(output_ck_translation_path, \"w\") as f:\n",
    "    json.dump(mean_dict, f, indent=4)  # JSON 파일로 저장 (들여쓰기 포함)\n",
    "\n",
    "\n",
    "# ECEF .ply 파일로 저장\n",
    "o3d.io.write_point_cloud(output_webgui_ply_path, webgui_pcd)\n",
    "print(f\"webgui Transformed point cloud saved to: {output_webgui_ply_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Loaded dataparser_transform in 0.01 seconds\n",
      "Loaded ECEF transform in 0.00 seconds\n",
      "Maximum in inverse_indices: 208191\n",
      "Original Vertex Shape: (342598, 3)\n",
      "New Vertex Shape: (208192, 3)\n",
      "Loaded OBJ mesh in 10.77 seconds\n",
      "Converted to ECEF in 2099.12 seconds\n",
      "Converted to UTM in 0.12 seconds\n",
      "Converted to central korea in 0.14 seconds\n",
      "ECEF Transformed mesh saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/mesh_ecef.obj\n",
      "UTM Transformed mesh saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/mesh_utm.obj\n",
      "CK Transformed mesh saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/mesh_ck.obj\n",
      "Saved transformed meshes in 39.27 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3D NeRFStudio mesh -> ECEF/UTM Translation\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from R3DR.utils.colmap_utils import qvec2rotmat\n",
    "import time\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import os\n",
    "\n",
    "def homogeneous(c2w):\n",
    "    if len(c2w) == 3:        \n",
    "        c2w = np.vstack([c2w, [0, 0, 0, 1]])\n",
    "    return c2w\n",
    "\n",
    "def sim3_matrix(scale, rotation, translation):\n",
    "    \"\"\"\n",
    "    Make a general sim3 matrix (scale -> rotation -> translation)\n",
    "    \"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * rotation \n",
    "    T[:3, 3] = translation    \n",
    "    return T\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for ECEF to UTM conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to UTM coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    points_utm = np.stack([e, n, alt], axis = -1) \n",
    "    \n",
    "    return points_utm\n",
    "\n",
    "def ecef_to_central_korea_transformer():\n",
    "    \"\"\"Creates a Transformer for ECEF to EPSG:5186 (중부원점) conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", \"EPSG:5186\", always_xy=True)\n",
    "\n",
    "def ecef_to_central_korea_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to 중부원점 (EPSG:5186) coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "\n",
    "def ecef_to_enu_rotation_matrix(lat_deg, lon_deg):\n",
    "    \"\"\"\n",
    "    위도/경도로 정의된 ENU 기준 좌표계에 대한 ECEF → ENU 회전 행렬 생성\n",
    "    \"\"\"\n",
    "    lat = np.radians(lat_deg)\n",
    "    lon = np.radians(lon_deg)\n",
    "\n",
    "    R = np.array([\n",
    "        [-np.sin(lon),              np.cos(lon),              0],\n",
    "        [-np.sin(lat)*np.cos(lon), -np.sin(lat)*np.sin(lon), np.cos(lat)],\n",
    "        [np.cos(lat)*np.cos(lon),  np.cos(lat)*np.sin(lon),  np.sin(lat)]\n",
    "    ])\n",
    "    return R  # 3x3 matrix\n",
    "\n",
    "\n",
    "def ecef_to_latlonalt(x, y, z):\n",
    "    transformer = Transformer.from_crs(\"epsg:4978\", \"epsg:4326\", always_xy=True)  # ECEF → WGS84\n",
    "    lon, lat, alt = transformer.transform(x, y, z)\n",
    "    return lat, lon, alt\n",
    "\n",
    "def normalize_coordinates(coords):\n",
    "    \"\"\"\n",
    "    좌표 배열에서 각 축의 평균을 계산한 후, 이를 원래 좌표에서 뺀 값을 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        coords (numpy.ndarray): (n, 3) 형태의 좌표 배열.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: 평균이 제거된 (n, 3) 형태의 좌표 배열.\n",
    "    \"\"\"\n",
    "    mean_coords = np.mean(coords, axis=0)  # 각 축(x, y, z)의 평균 계산\n",
    "    normalized_coords = coords - mean_coords  # 평균을 빼서 원점 기준 정규화\n",
    "    return normalized_coords, mean_coords\n",
    "\n",
    "\n",
    "# Open3D의 mesh load시, Vertex 중복 문제를 해소하기 위함(Texture mapping을 위한 코드)\n",
    "def remove_duplicate_vertices(mesh):\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    triangles = np.asarray(mesh.triangles)\n",
    "    triangle_uvs = np.asarray(mesh.triangle_uvs)\n",
    "    vertex_normals = np.asarray(mesh.vertex_normals)\n",
    "    \n",
    "    # 중복 제거를 위한 dict (순서 보존) np.unique는 자동 sort되어 순서기반 mapping이 깨짐\n",
    "    unique_vertex_map = {}  \n",
    "    new_vertices = []\n",
    "    inverse_indices = np.zeros(len(vertices), dtype=int)\n",
    "\n",
    "    for i, v in enumerate(vertices):\n",
    "        v_tuple = tuple(v)  # 리스트를 튜플로 변환 (딕셔너리 key로 사용)\n",
    "        if v_tuple not in unique_vertex_map:\n",
    "            unique_vertex_map[v_tuple] = len(new_vertices)\n",
    "            new_vertices.append(v)\n",
    "        inverse_indices[i] = unique_vertex_map[v_tuple]\n",
    "    print(f\"Maximum in inverse_indices: {np.max(inverse_indices)}\")\n",
    "    new_vertices = np.array(new_vertices)\n",
    "    new_triangles = inverse_indices[triangles]\n",
    "    assert triangles.shape == new_triangles.shape # 실제로 중복된 면은 없다.\n",
    "\n",
    "    new_triangle_uvs = triangle_uvs.copy()\n",
    "    new_triangle_uvs[:, 1] = 1.0 - new_triangle_uvs[:, 1]  # Y축 뒤집기 (Open3D와 다른 mesh 소프트웨어 간 UV 정의 차이 보정)\n",
    "\n",
    "    \n",
    "    print(f\"Original Vertex Shape: {vertices.shape}\")\n",
    "    print(f\"New Vertex Shape: {new_vertices.shape}\")\n",
    "\n",
    "    # 정점 병합 후, 법선 평균 처리\n",
    "    new_normals = np.zeros_like(new_vertices, dtype=np.float64)\n",
    "    normal_counts = np.zeros(len(new_vertices), dtype=int)\n",
    "\n",
    "    for old_idx, new_idx in enumerate(inverse_indices):\n",
    "        new_normals[new_idx] += vertex_normals[old_idx]\n",
    "        normal_counts[new_idx] += 1\n",
    "\n",
    "    new_normals /= normal_counts[:, None]  # 정규화        \n",
    "    \n",
    "    # Open3D mesh 갱신\n",
    "    new_mesh = o3d.geometry.TriangleMesh()\n",
    "    new_mesh.vertices = o3d.utility.Vector3dVector(new_vertices)\n",
    "    new_mesh.triangles = o3d.utility.Vector3iVector(new_triangles)\n",
    "    new_mesh.triangle_uvs = o3d.utility.Vector2dVector(new_triangle_uvs)\n",
    "    new_mesh.vertex_normals = o3d.utility.Vector3dVector(new_normals)\n",
    "    \n",
    "    return new_mesh\n",
    "\n",
    "# -------------------------------\n",
    "# 📌 .OBJ 메쉬 파일 변환 코드\n",
    "# -------------------------------\n",
    "def transform_mesh_obj(input_obj_path, texture_path, output_path, T_ecef_webgui_sim3, zone_number=52, zone_letter=\"north\"):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_ecef_obj_path = os.path.join(output_path, \"mesh_ecef.obj\")\n",
    "    output_utm_obj_path = os.path.join(output_path, \"mesh_utm.obj\")\n",
    "    output_ck_obj_path = os.path.join(output_path, \"mesh_ck.obj\")\n",
    "    output_ecef_translation_path = os.path.join(output_path, \"translation_ecef.json\")\n",
    "    output_utm_translation_path = os.path.join(output_path, \"translation_utm.json\")\n",
    "    output_ck_translation_path = os.path.join(output_path, \"translation_ck.json\")\n",
    "\n",
    "    # 1️⃣ .OBJ 파일 로드\n",
    "    mesh = o3d.io.read_triangle_mesh(input_obj_path) \n",
    "    \n",
    "    new_mesh = remove_duplicate_vertices(mesh)   \n",
    "\n",
    "    image = o3d.io.read_image(texture_path)  # 텍스처 로드\n",
    "    new_mesh.textures = [o3d.geometry.Image(image)]  # 텍스처 적용\n",
    "\n",
    "    vertices = np.asarray(new_mesh.vertices)    \n",
    "    normals = np.asarray(new_mesh.vertex_normals)\n",
    "    \n",
    "    print(f\"Loaded OBJ mesh in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 2️⃣ ECEF 변환 적용\n",
    "    start_time = time.time()\n",
    "    coords = np.hstack([vertices, np.ones((vertices.shape[0], 1))])  # (N, 4)\n",
    "    normals_homo = np.hstack([normals, np.zeros((normals.shape[0], 1))])  # (N, 4)\n",
    "    assert coords.dtype == np.float64\n",
    "    \n",
    "    coords_ecef = (T_ecef_webgui_sim3[:3, :] @ coords.T).T  # ECEF 좌표 변환 (N, 3)\n",
    "    normals_ecef = (T_ecef_webgui_sim3[:3, :] @ normals_homo.T).T  # ECEF 좌표 변환 (N, 3)\n",
    "    normals_ecef /=  np.linalg.norm(normals_ecef)\n",
    "\n",
    "    latlonalts = []\n",
    "    for x, y, z in coords_ecef:\n",
    "        latlonalts.append(ecef_to_latlonalt(x, y, z))    \n",
    "    latlonalts = np.asarray(latlonalts) # (N, 3)\n",
    "\n",
    "    normals_enu = []\n",
    "    for (lat, lon, alt), normal_ecef in zip(latlonalts, normals_ecef):\n",
    "        R_ecef2enu = ecef_to_enu_rotation_matrix(lat, lon)\n",
    "        normals_enu.append(R_ecef2enu @ normal_ecef)\n",
    "\n",
    "    print(f\"Converted to ECEF in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 3️⃣ ECEF → UTM 변환\n",
    "    start_time = time.time()\n",
    "    transformer = ecef_to_utm_transformer(zone_number, zone_letter)\n",
    "    coords_utm = ecef_to_utm_points(coords_ecef, transformer)\n",
    "\n",
    "    print(f\"Converted to UTM in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 중부원점 변환\n",
    "    start_time = time.time()\n",
    "    transformer_central_korea = ecef_to_central_korea_transformer()\n",
    "    coords_ck = ecef_to_central_korea_points(coords_ecef, transformer_central_korea)\n",
    "    print(f\"Converted to central korea in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 4️⃣ 변환된 좌표를 Open3D Mesh로 저장\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ECEF 변환 후 저장\n",
    "    ecef_mesh = copy.deepcopy(new_mesh)\n",
    "    coords_ecef, ecef_global_translation = normalize_coordinates(coords_ecef)\n",
    "    ecef_mesh.vertices = o3d.utility.Vector3dVector(coords_ecef)    \n",
    "    ecef_mesh.vertex_normals = o3d.utility.Vector3dVector(normals_ecef)    \n",
    "    o3d.io.write_triangle_mesh(output_ecef_obj_path, ecef_mesh, \n",
    "        write_ascii=True,\n",
    "        compressed=False,      # 압축 없이 저장 (정밀도 유지)\n",
    "        write_vertex_normals=True,  # 법선 포함\n",
    "        write_vertex_colors=False,  # 색상 포함 X (필요한 경우 True)\n",
    "        write_triangle_uvs=True     # UV 좌표 강제 포함\n",
    "    )\n",
    "    mean_dict = {\"global_translation\": ecef_global_translation.tolist()}\n",
    "\n",
    "    with open(output_ecef_translation_path, \"w\") as f:\n",
    "        json.dump(mean_dict, f, indent=4)  # JSON 파일로 저장 (들여쓰기 포함)\n",
    "    \n",
    "    print(f\"ECEF Transformed mesh saved to: {output_ecef_obj_path}\")\n",
    "\n",
    "    # UTM 변환 후 저장\n",
    "    utm_mesh = copy.deepcopy(new_mesh)    \n",
    "    coords_utm, utm_global_translation = normalize_coordinates(coords_utm)\n",
    "    utm_mesh.vertices = o3d.utility.Vector3dVector(coords_utm)        \n",
    "    utm_mesh.vertex_normals = o3d.utility.Vector3dVector(normals_enu)\n",
    "    o3d.io.write_triangle_mesh(output_utm_obj_path, utm_mesh, \n",
    "        write_ascii=True,\n",
    "        compressed=False,      # 압축 없이 저장 (정밀도 유지)\n",
    "        write_vertex_normals=True,  # 법선 포함\n",
    "        write_vertex_colors=False,  # 색상 포함 X (필요한 경우 True)\n",
    "        write_triangle_uvs=True     # UV 좌표 강제 포함\n",
    "    )\n",
    "    mean_dict = {\"global_translation\": utm_global_translation.tolist()}\n",
    "\n",
    "    with open(output_utm_translation_path, \"w\") as f:\n",
    "        json.dump(mean_dict, f, indent=4)  # JSON 파일로 저장 (들여쓰기 포함)\n",
    "        \n",
    "    print(f\"UTM Transformed mesh saved to: {output_utm_obj_path}\")\n",
    "\n",
    "    # CK 변환 후 저장\n",
    "    ck_mesh = copy.deepcopy(new_mesh)    \n",
    "    coords_ck, ck_global_translation = normalize_coordinates(coords_ck)\n",
    "    ck_mesh.vertices = o3d.utility.Vector3dVector(coords_ck)        \n",
    "    ck_mesh.vertex_normals = o3d.utility.Vector3dVector(normals_enu)\n",
    "    o3d.io.write_triangle_mesh(output_ck_obj_path, ck_mesh, \n",
    "        write_ascii=True,\n",
    "        compressed=False,      # 압축 없이 저장 (정밀도 유지)\n",
    "        write_vertex_normals=True,  # 법선 포함\n",
    "        write_vertex_colors=False,  # 색상 포함 X (필요한 경우 True)\n",
    "        write_triangle_uvs=True     # UV 좌표 강제 포함\n",
    "    )\n",
    "    mean_dict = {\"global_translation\": ck_global_translation.tolist()}\n",
    "\n",
    "    with open(output_ck_translation_path, \"w\") as f:\n",
    "        json.dump(mean_dict, f, indent=4)  # JSON 파일로 저장 (들여쓰기 포함)\n",
    "        \n",
    "    print(f\"CK Transformed mesh saved to: {output_ck_obj_path}\")\n",
    "\n",
    "    print(f\"Saved transformed meshes in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "dataparser_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/ns_processed/nerfacto/2025-05-08_071846/dataparser_transforms.json\"\n",
    "ecef_transforms_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/ns_processed/colmap/sparse/geo-registration/ecef/sim3_transform.json\"\n",
    "\n",
    "obj_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/mesh.obj\"\n",
    "\n",
    "texture_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/material_0.png\"  # 텍스처 파일 경로\n",
    "\n",
    "output_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# dataparser_transforms.json 읽기\n",
    "with open(dataparser_transforms_path, 'r') as file:\n",
    "    dataparser_tform = json.load(file)\n",
    "\n",
    "\n",
    "T_webgui_colmap = homogeneous(np.array(dataparser_tform['transform'])) # (4, 4), dataparser_transform(T_webgui_colmap) = orient_pose_transform(T_webgui_nerf) @ applied_transform(T_nerf_colmap)\n",
    "scale = dataparser_tform['scale']\n",
    "\n",
    "\n",
    "# Sim(3) 변환 행렬 생성\n",
    "# NeRFStudio Sim3 정의 상, R, t 먼저 적용 후 전체 scaling\n",
    "T_webgui_colmap_sim3 = T_webgui_colmap.copy()\n",
    "T_webgui_colmap_sim3[:3, :] *= scale\n",
    "T_colmap_webgui_sim3 = np.linalg.inv(T_webgui_colmap_sim3)\n",
    "\n",
    "print(f\"Loaded dataparser_transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ecef_transforms.json 읽기\n",
    "with open(ecef_transforms_path, 'r') as file:\n",
    "    ecef_tform = file.read().strip()\n",
    "\n",
    "scale, q0, q1, q2, q3, tx, ty, tz = map(np.float64, ecef_tform.split(\" \")) # 13.708695938967331 0.44253099182081379 0.83353368302085051 0.31283289113402335 0.10734757925780858 -3047518.2350821388 4051223.3963172659 3857848.7263354594\n",
    "rot = qvec2rotmat(np.array([q0, q1, q2, q3]))\n",
    "trans = np.array([tx, ty, tz])\n",
    "\n",
    "# Sim(3) 변환 행렬 생성 (scale first)\n",
    "T_ecef_colmap_sim3 = sim3_matrix(scale, rot, trans)\n",
    "\n",
    "T_ecef_webgui_sim3 = T_ecef_colmap_sim3 @ T_colmap_webgui_sim3\n",
    "\n",
    "print(f\"Loaded ECEF transform in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "transform_mesh_obj(obj_path, texture_path, output_path, T_ecef_webgui_sim3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCD Post-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9998607 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/original/point_cloud_utm.ply\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# .ply 파일 로드\n",
    "workspace_dir = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial\"\n",
    "input_ply_path = os.path.join(workspace_dir,'nerf_output/exports/pcd/original/point_cloud_utm.ply')\n",
    "\n",
    "# 저장할 .ply 파일 경로\n",
    "output_dir = os.path.join(workspace_dir,'nerf_output/exports/pcd/filtered')\n",
    "# 디렉토리 생성 (존재하지 않으면)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_ply_path = os.path.join(output_dir, 'filtered_utm.ply')\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "print(f\"Loaded {len(pcd.points)} points from {input_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No filtering applied. Total points: 9998607\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ====== 함수 정의 ======\n",
    "def filter_points_in_polygon(point_cloud_xy, polygon_xy):\n",
    "    polygon = Polygon(polygon_xy)\n",
    "    ind = np.array([polygon.contains(Point(x, y)) for x, y in point_cloud_xy])\n",
    "    return ind\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    return np.stack([e, n, alt], axis=-1)\n",
    "\n",
    "def geodetic_to_ecef(lat, lon, alt=0.0):\n",
    "    a = 6378137.0\n",
    "    e2 = 6.69437999014e-3\n",
    "    lat_rad = np.radians(lat)\n",
    "    lon_rad = np.radians(lon)\n",
    "    N = a / np.sqrt(1 - e2 * np.sin(lat_rad)**2)\n",
    "    x = (N + alt) * np.cos(lat_rad) * np.cos(lon_rad)\n",
    "    y = (N + alt) * np.cos(lat_rad) * np.sin(lon_rad)\n",
    "    z = (N * (1 - e2) + alt) * np.sin(lat_rad)\n",
    "    return x, y, z\n",
    "\n",
    "# ====== 설정 ======\n",
    "use_gps_filtering = False  # 🚩 True: 필터링 사용, False: 전체 사용\n",
    "\n",
    "target_gps_coords = np.array([\n",
    "    [37.47045, 126.9582],\n",
    "    [37.47051, 126.9593],\n",
    "    [37.47242, 126.9594],\n",
    "    [37.47242, 126.9583]\n",
    "])\n",
    "# ==================\n",
    "\n",
    "target_ecef_coords = np.array([geodetic_to_ecef(lat, lon) for lat, lon in target_gps_coords])\n",
    "transformer = ecef_to_utm_transformer(zone_number=52, zone_letter=\"north\")\n",
    "target_utm_coords = ecef_to_utm_points(target_ecef_coords, transformer)\n",
    "\n",
    "# ====== 포인트 클라우드 준비 ======\n",
    "points = np.asarray(pcd.points).astype(np.float64)\n",
    "colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "if use_gps_filtering:\n",
    "    # (1) x, y 추출\n",
    "    points_utm = ecef_to_utm_points(points, transformer)\n",
    "    point_xy = points_utm[:, :2]\n",
    "\n",
    "    # (2) 마스크 생성\n",
    "    inside_ind = filter_points_in_polygon(point_xy, target_utm_coords)\n",
    "\n",
    "    # (3) 필터링 적용\n",
    "    inside_points = points[inside_ind]\n",
    "    inside_colors = colors[inside_ind] if colors is not None else None\n",
    "    inside_normals = normals[inside_ind] if normals is not None else None\n",
    "\n",
    "    print(f\"Filtered point numbers: {len(inside_points)}\")\n",
    "else:\n",
    "    # 필터링 없이 전체 사용\n",
    "    inside_points = points\n",
    "    inside_colors = colors\n",
    "    inside_normals = normals\n",
    "    print(f\"No filtering applied. Total points: {len(inside_points)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered hegiht range: 48.9842511492743 ~ 108.69018882876587\n",
      "Filtered point numbers: 9004462\n"
     ]
    }
   ],
   "source": [
    "# 1. Height-based Filetering\n",
    "\n",
    "# 높이가 0m 이상인 포인트만 필터링\n",
    "filtered_indices = inside_points[:, 2] >= -100.0  # Z 값이 thr 이상인 인덱스를 찾음\n",
    "filtered_points = inside_points[filtered_indices]  # Z 값이 thr 이상인 포인트들만 선택\n",
    "\n",
    "# 3. 통계적으로 높이 범위 벗어나는 노이즈 제거\n",
    "z_values = filtered_points[:, 2]  # Z 값만 추출\n",
    "mean_z = np.mean(z_values)\n",
    "std_z = np.std(z_values)\n",
    "\n",
    "# 예시: 평균 ± 3 * 표준편차 범위 내의 포인트들만 남김\n",
    "z_threshold_upper = mean_z + 3 * std_z\n",
    "z_threshold_lower = mean_z - 1.5 * std_z\n",
    "\n",
    "print(f\"Filtered hegiht range: {z_threshold_lower} ~ {z_threshold_upper}\")\n",
    "# 범위 밖의 포인트 제거\n",
    "final_filtered_indices = (z_values >= z_threshold_lower) & (z_values <= z_threshold_upper)\n",
    "filtered_points = filtered_points[final_filtered_indices]\n",
    "\n",
    "# 색상 및 법선 벡터도 필터링\n",
    "if colors is not None:\n",
    "    filtered_colors = inside_colors[filtered_indices][final_filtered_indices]\n",
    "else:\n",
    "    filtered_colors = None\n",
    "\n",
    "if normals is not None:\n",
    "    filtered_normals = inside_normals[filtered_indices][final_filtered_indices]\n",
    "else:\n",
    "    filtered_normals = None\n",
    "\n",
    "filtered_pcd = o3d.geometry.PointCloud()\n",
    "filtered_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "# 색상 및 법선 벡터도 필터링한 값으로 업데이트\n",
    "if filtered_colors is not None:\n",
    "    filtered_pcd.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "if filtered_normals is not None:\n",
    "    filtered_pcd.normals = o3d.utility.Vector3dVector(filtered_normals)\n",
    "    \n",
    "# 필터링된 포인트 수 출력\n",
    "print(f\"Filtered point numbers: {len(filtered_points)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOR Filtered point count: 8179208\n",
      "Point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/250526_STEAM_Naju_workspace/250526_earthwork_90m_correct_trial2/initial/nerf_output/exports/pcd/filtered/filtered_utm.ply\n"
     ]
    }
   ],
   "source": [
    "# 2. SOR (Statistical Outlier Removal) 노이즈 제거\n",
    "nb_neighbors = 20  # 각 포인트에 대해 고려할 이웃 포인트의 개수\n",
    "std_ratio = 1.0    # 표준편차를 기준으로 이상치 제거 기준 (표준편차 배수)\n",
    "\n",
    "\n",
    "# remove_statistical_outlier는 포인트 수와 인덱스를 반환\n",
    "sor_pcd, sor_idx = filtered_pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "print(f\"SOR Filtered point count: {len(sor_pcd.points)}\")\n",
    "\n",
    "# .ply 파일로 저장\n",
    "o3d.io.write_point_cloud(output_ply_path, sor_pcd)\n",
    "print(f\"Point cloud saved to: {output_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 포인트 수: 6942341\n",
      "다운샘플 후: 3561756\n"
     ]
    }
   ],
   "source": [
    "# EXT-3. grid-based downsample\n",
    "import numpy as np\n",
    "\n",
    "def grid_downsample_mean_z_with_attributes(points, colors=None, normals=None, grid_size=0.01):\n",
    "    \"\"\"\n",
    "    포인트 클라우드를 그리드 단위로 다운샘플링하고, z 평균으로 하나의 점을 남긴다.\n",
    "    colors와 normals도 각각 평균으로 병합 (선택사항)\n",
    "\n",
    "    Returns:\n",
    "        down_points: (M, 3)\n",
    "        down_colors: (M, 3) or None\n",
    "        down_normals: (M, 3) or None\n",
    "    \"\"\"\n",
    "    xy_indices = np.floor(points[:, :2] / grid_size).astype(np.int32)\n",
    "    keys = [tuple(idx) for idx in xy_indices]\n",
    "\n",
    "    grid_dict = {}\n",
    "    for i, key in enumerate(keys):\n",
    "        if key not in grid_dict:\n",
    "            grid_dict[key] = {\n",
    "                \"z_list\": [],\n",
    "                \"color_list\": [],\n",
    "                \"normal_list\": []\n",
    "            }\n",
    "        grid_dict[key][\"z_list\"].append(points[i, 2])\n",
    "        if colors is not None:\n",
    "            grid_dict[key][\"color_list\"].append(colors[i])\n",
    "        if normals is not None:\n",
    "            grid_dict[key][\"normal_list\"].append(normals[i])\n",
    "\n",
    "    down_points, down_colors, down_normals = [], [], []\n",
    "    for key, val in grid_dict.items():\n",
    "        key = np.array(key, dtype=np.float64)\n",
    "        x_center = (key[0] + 0.5) * grid_size\n",
    "        y_center = (key[1] + 0.5) * grid_size        \n",
    "        z_mean = np.mean(val[\"z_list\"])\n",
    "        down_points.append([x_center, y_center, z_mean])\n",
    "\n",
    "        if colors is not None:\n",
    "            down_colors.append(np.mean(val[\"color_list\"], axis=0))\n",
    "        if normals is not None:\n",
    "            down_normals.append(np.mean(val[\"normal_list\"], axis=0))\n",
    "\n",
    "    return (\n",
    "        np.array(down_points),\n",
    "        np.array(down_colors) if colors is not None else None,\n",
    "        np.array(down_normals) if normals is not None else None\n",
    "    )\n",
    "\n",
    "sor_points = np.asarray(sor_pcd.points).astype(np.float64)\n",
    "sor_colors = filtered_colors[sor_idx]\n",
    "sor_normals = filtered_normals[sor_idx]\n",
    "down_points, down_colors, down_normals = grid_downsample_mean_z_with_attributes(sor_points, sor_colors, sor_normals, grid_size=0.05)\n",
    "\n",
    "# 4. 필터링된 포인트 클라우드로 업데이트\n",
    "down_pcd = o3d.geometry.PointCloud()\n",
    "down_pcd.points = o3d.utility.Vector3dVector(down_points)\n",
    "\n",
    "# 색상 및 법선 벡터도 필터링한 값으로 업데이트\n",
    "if down_colors is not None:\n",
    "    down_pcd.colors = o3d.utility.Vector3dVector(down_colors)\n",
    "\n",
    "if down_normals is not None:\n",
    "    down_pcd.normals = o3d.utility.Vector3dVector(down_normals)\n",
    "\n",
    "output_ply_path = os.path.join(workspace_dir,'nerf_output/exports/pcd/filtered/grid_filtered_utm.ply')\n",
    "\n",
    "# .ply 파일로 저장\n",
    "o3d.io.write_point_cloud(output_ply_path, down_pcd)\n",
    "\n",
    "print(\"원래 포인트 수:\", len(sor_points))\n",
    "print(\"다운샘플 후:\", down_points.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[299877.0, 3874302.0, 300300.0, 3874898.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     min_max \u001b[38;5;241m=\u001b[39m (x_min, y_min, x_max, y_max)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m min_max, grid_colors \u001b[38;5;66;03m#(num of grid points, 3)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m min_max_color_phase, grid_colors \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_interpolate_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_pcd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mpatch_interpolate_color\u001b[0;34m(pcd)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m([x_min, y_min, x_max, y_max])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 그리드의 해상도 정의\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m grid_x, grid_y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_max\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_max\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 0.05m 간격의 그리드\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 4. 보간을 위한 데이터 준비\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 기존 포인트의 x, y 값\u001b[39;00m\n\u001b[1;32m     24\u001b[0m xy_points \u001b[38;5;241m=\u001b[39m points[:, :\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/nerfstudio/lib/python3.8/site-packages/numpy/lib/index_tricks.py:174\u001b[0m, in \u001b[0;36mnd_grid.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    171\u001b[0m     nn \u001b[38;5;241m=\u001b[39m [_nx\u001b[38;5;241m.\u001b[39marange(_x, dtype\u001b[38;5;241m=\u001b[39m_t)\n\u001b[1;32m    172\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m _x, _t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(size, (typ,)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(size))]\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     nn \u001b[38;5;241m=\u001b[39m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, kk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    176\u001b[0m     step \u001b[38;5;241m=\u001b[39m kk\u001b[38;5;241m.\u001b[39mstep\n",
      "File \u001b[0;32m~/.conda/envs/nerfstudio/lib/python3.8/site-packages/numpy/core/numeric.py:1790\u001b[0m, in \u001b[0;36mindices\u001b[0;34m(dimensions, dtype, sparse)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         res \u001b[38;5;241m=\u001b[39m res \u001b[38;5;241m+\u001b[39m (idx,)\n\u001b[1;32m   1789\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1790\u001b[0m         \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. interpolate color\n",
    "import scipy\n",
    "\n",
    "\n",
    "def patch_interpolate_color(pcd):\n",
    "\n",
    "    # 1. 포인트 클라우드의 numpy 배열로 변환\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "\n",
    "    trunc_fun = lambda x: np.round(x) # ex. 1m precision\n",
    "\n",
    "    # 3. 평면 상에서 보간할 그리드 정의\n",
    "    x_min, y_min = trunc_fun(np.min(points[:, 0])), trunc_fun(np.min(points[:, 1]))\n",
    "    x_max, y_max = trunc_fun(np.max(points[:, 0])), trunc_fun(np.max(points[:, 1]))\n",
    "    \n",
    "    print([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    # 그리드의 해상도 정의\n",
    "    grid_x, grid_y = np.mgrid[x_min:x_max:0.05, y_min:y_max:0.05]  # 0.05m 간격의 그리드\n",
    "\n",
    "    # 4. 보간을 위한 데이터 준비\n",
    "    # 기존 포인트의 x, y 값\n",
    "    xy_points = points[:, :2]\n",
    "\n",
    "    # 6. Color 보간\n",
    "    grid_colors = np.empty((grid_x.shape[0], grid_x.shape[1], 3), dtype=np.float64)\n",
    "    for i in range(3):  # 각 채널(RGB)에 대해 보간\n",
    "        grid_colors[:, :, i] = scipy.interpolate.griddata(xy_points, colors[:, i], (grid_x, grid_y), method='nearest')\n",
    "    \n",
    "    \n",
    "    min_max = (x_min, y_min, x_max, y_max)\n",
    "    return min_max, grid_colors #(num of grid points, 3)\n",
    "\n",
    "min_max_color_phase, grid_colors = patch_interpolate_color(filtered_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4147475.85 4147551.97 4147429.86 4147419.11 4147479.66 4147416.16\n",
      " 4147493.76 4147413.16 4147520.45 4147401.08]\n",
      "Point cloud with rounded coordinates saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm_floor.ply\n"
     ]
    }
   ],
   "source": [
    "# 4. 소수점 아래 2번째 자리까지 반올림 -> 격자화\n",
    "\n",
    "# PointCloud의 점 데이터를 numpy 배열로 가져오기\n",
    "points = np.asarray(sor_pcd.points)\n",
    "\n",
    "# 소수점 아래 2자리까지만 남기고 나머지 제거\n",
    "rounded_points = np.trunc(points * 100) * 0.01\n",
    "print(rounded_points[:10, 1])\n",
    "# 소수점 아래 2자리까지 반올림한 점들을 다시 PointCloud 객체에 설정\n",
    "sor_pcd.points = o3d.utility.Vector3dVector(rounded_points)\n",
    "\n",
    "# 결과를 새로운 .ply 파일로 저장\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm_floor.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, sor_pcd)\n",
    "\n",
    "print(f\"Point cloud with rounded coordinates saved to: {output_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318799.0 4147372.0 318950.0 4147595.0\n",
      "0.0\n",
      "100.0\n",
      "60.0\n",
      "200.0\n",
      "(3020, 4460)\n",
      "(3020, 4460, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13887/607795458.py:52: RuntimeWarning: invalid value encountered in divide\n",
      "  grid_normals /= norm_magnitudes  # 정규화\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud saved to: /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_interpolate_utm.ply\n"
     ]
    }
   ],
   "source": [
    "# 5. patch_interpolate_z\n",
    "\n",
    "def patch_interpolate_z(pcd, min_max_color_phase, grid_colors, step=0.05):\n",
    "\n",
    "    # 1. 포인트 클라우드의 numpy 배열로 변환\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "    normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "    trunc_fun = lambda x: np.round(x) # ex. 1m precision\n",
    "    # 3. 평면 상에서 보간할 그리드 정의\n",
    "    x_min, y_min = trunc_fun(np.min(points[:, 0])), trunc_fun(np.min(points[:, 1]))\n",
    "    x_max, y_max = trunc_fun(np.max(points[:, 0])), trunc_fun(np.max(points[:, 1]))\n",
    "\n",
    "    # 그리드의 해상도 정의\n",
    "    grid_x, grid_y = np.mgrid[x_min:x_max:step, y_min:y_max:step]  # 0.05m 간격의 그리드\n",
    "\n",
    "    # 4. 보간을 위한 데이터 준비\n",
    "    # 기존 포인트의 x, y 값\n",
    "    xy_points = points[:, :2]\n",
    "\n",
    "    # z 값은 모두 0, 주변값을 기준으로 보간할 예정\n",
    "    z_values = points[:, 2]\n",
    "\n",
    "    # 5. 보간: griddata 사용하여 빈공간을 채우기\n",
    "    # 방법: 'linear', 'cubic', 'nearest' 등을 사용할 수 있음\n",
    "    grid_z = scipy.interpolate.griddata(xy_points, z_values, (grid_x, grid_y), method='nearest')\n",
    "\n",
    "    # 6. Color 보간\n",
    "    c_x_min, c_y_min, c_x_max, c_y_max = min_max_color_phase\n",
    "    x_min_ind = int(trunc_fun((x_min - c_x_min)/step))\n",
    "    y_min_ind = int(trunc_fun((y_min - c_y_min)/step))\n",
    "    x_max_ind = grid_colors.shape[0] - int(trunc_fun((c_x_max - x_max)/step))\n",
    "    y_max_ind = grid_colors.shape[1] - int(trunc_fun((c_y_max - y_max)/step))\n",
    "    grid_colors = grid_colors[x_min_ind:x_max_ind, y_min_ind:y_max_ind]\n",
    "    \n",
    "\n",
    "    \n",
    "    # 7. Normal 보간\n",
    "    grid_normals = np.empty((grid_x.shape[0], grid_x.shape[1], 3), dtype=np.float64)\n",
    "    for i in range(3):  # 각 노멀 벡터 성분에 대해 보간\n",
    "        grid_normals[:, :, i] = scipy.interpolate.griddata(xy_points, normals[:, i], (grid_x, grid_y), method='nearest')\n",
    "\n",
    "    # 보간 후, 노멀 벡터를 단위 벡터로 정규화\n",
    "    norm_magnitudes = np.linalg.norm(grid_normals, axis=2, keepdims=True)\n",
    "    grid_normals /= norm_magnitudes  # 정규화\n",
    "\n",
    "    # 8. 보간된 결과를 3D 포인트 클라우드로 변환\n",
    "    interpolated_points = np.vstack((grid_x.flatten(), grid_y.flatten(), grid_z.flatten())).T\n",
    "    interpolated_colors = grid_colors.reshape(-1, 3)\n",
    "    interpolated_normals = grid_normals.reshape(-1, 3)\n",
    "\n",
    "    # 9. Open3D 포인트 클라우드 객체로 변환\n",
    "    interpolated_pcd = o3d.geometry.PointCloud()\n",
    "    interpolated_pcd.points = o3d.utility.Vector3dVector(interpolated_points)\n",
    "    interpolated_pcd.colors = o3d.utility.Vector3dVector(interpolated_colors)\n",
    "    interpolated_pcd.normals = o3d.utility.Vector3dVector(interpolated_normals)\n",
    "\n",
    "    return interpolated_pcd\n",
    "\n",
    "interpolated_pcd = patch_interpolate_z(sor_pcd, min_max_color_phase, grid_colors)\n",
    "\n",
    "# 결과를 새로운 .ply 파일로 저장\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_interpolate_utm.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, interpolated_pcd)\n",
    "\n",
    "print(f\"Point cloud saved to: {output_ply_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Patch-based Plane Interpolation\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# 포인트 클라우드를 X, Y 기준으로 나누기 위한 함수\n",
    "def split_point_cloud(pcd, x_step=1.0, y_step=1.0):\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else None\n",
    "    normals = np.asarray(pcd.normals) if pcd.has_normals() else None\n",
    "\n",
    "    x_min, y_min = np.min(points[:, 0]), np.min(points[:, 1])\n",
    "    x_max, y_max = np.max(points[:, 0]), np.max(points[:, 1])\n",
    "\n",
    "    # X, Y 범위에 맞게 그리드 정의\n",
    "    x_range = np.arange(x_min, x_max, x_step)\n",
    "    y_range = np.arange(y_min, y_max, y_step)\n",
    "\n",
    "    # 그리드 상에 포인트 클라우드를 분할\n",
    "    sub_clouds = []\n",
    "    for x_start in x_range:\n",
    "        for y_start in y_range:\n",
    "            # 현재 그리드에 해당하는 점들을 필터링\n",
    "            mask = (points[:, 0] >= x_start) & (points[:, 0] < x_start + x_step) & \\\n",
    "                   (points[:, 1] >= y_start) & (points[:, 1] < y_start + y_step)\n",
    "\n",
    "            sub_points = points[mask]            \n",
    "            sub_colors = colors[mask]\n",
    "            sub_normals = normals[mask]\n",
    "\n",
    "            if len(sub_points) > 0:  # 포인트가 존재하는 경우\n",
    "                sub_pcd = o3d.geometry.PointCloud()\n",
    "                sub_pcd.points = o3d.utility.Vector3dVector(sub_points)\n",
    "                sub_pcd.colors = o3d.utility.Vector3dVector(sub_colors)\n",
    "                sub_pcd.normals = o3d.utility.Vector3dVector(sub_normals)\n",
    "                sub_clouds.append(sub_pcd)\n",
    "\n",
    "    return sub_clouds\n",
    "\n",
    "\n",
    "\n",
    "# 예시 포인트 클라우드 로드 (sor_pcd는 이미 정리된 포인트 클라우드)\n",
    "\n",
    "input_ply_path = '/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply'\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "\n",
    "# 포인트 클라우드를 x, y 기준으로 나누기\n",
    "splited_sub_clouds = split_point_cloud(pcd, x_step=5, y_step=5)  # 원하는 크기만큼 잘라서 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94030/910921686.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  grid_normals /= norm_magnitudes  # 정규화\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plane 추출\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "\n",
    "def sub_pointcloud_interpolation(sub_clouds, inlier_thr = 0.8):\n",
    "    cnt = 0\n",
    "    max_ratio = 0.0\n",
    "    interpolated_sub_clouds = []\n",
    "    for pcd in sub_clouds:\n",
    "        if(len(pcd.points) <3):\n",
    "            # print(\"too small pcd\")\n",
    "            continue\n",
    "        plane_model, inliers = pcd.segment_plane(distance_threshold=0.10,\n",
    "                                                ransac_n=3,\n",
    "                                                num_iterations=1000)\n",
    "        [a, b, c, d] = plane_model\n",
    "        # print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "        \n",
    "        total = len(pcd.points)\n",
    "        inlier_ratio = len(inliers)/ total\n",
    "        if(max_ratio < inlier_ratio):\n",
    "            max_ratio = inlier_ratio\n",
    "\n",
    "        if(inlier_ratio >= inlier_thr):\n",
    "            cnt += 1        \n",
    "            inlier_pcd = pcd.select_by_index(inliers)\n",
    "            interpolated_pcd = patch_interpolate(inlier_pcd)\n",
    "            interpolated_sub_clouds.append(interpolated_pcd)\n",
    "\n",
    "    print(cnt)\n",
    "    print(max_ratio)\n",
    "    points = np.empty((0, 3))\n",
    "    colors = np.empty((0, 3))\n",
    "    normals = np.empty((0, 3))\n",
    "    for sub_pcd in interpolated_sub_clouds:\n",
    "        points = np.vstack((points, sub_pcd.points))\n",
    "        colors = np.vstack((colors, sub_pcd.colors))\n",
    "        normals = np.vstack((normals, sub_pcd.normals))\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "    return pcd\n",
    "\n",
    "# .ply 파일로 저장\n",
    "inlier_thr = 0.4\n",
    "pcd = sub_pointcloud_interpolation(splited_sub_clouds, inlier_thr)\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/test/test.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Loaded 5757153 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] /root/Open3D/build/poisson/src/ext_poisson/PoissonRecon/Src/FEMTree.IsoSurface.specialized.inl (Line 1858)\n",
      "          Extract\n",
      "          bad average roots: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "pcd, depth=9)\n",
    "\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/test/test.ply\"\n",
    "o3d.io.write_triangle_mesh(output_ply_path, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5757153 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "input_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "print(f\"Loaded {len(pcd.points)} points from {input_ply_path}\")\n",
    "\n",
    "pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/test/test.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7724974 points from /workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECEF to UTM\n",
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "def utm_to_ecef_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for UTM to ECEF conversion.\"\"\"\n",
    "    return Transformer.from_crs(f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\", \"EPSG:4978\")\n",
    "\n",
    "def utm_to_ecef_points(points_utm: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts UTM points to ECEF coordinates.\n",
    "    \n",
    "    points_utm : (N, 3) - UTM coordinates (E, N, Altitude)\n",
    "    \"\"\"\n",
    "    \n",
    "    e, n, alt = points_utm[:, 0], points_utm[:, 1], points_utm[:, 2]\n",
    "    x, y, z = transformer.transform(e, n, alt)\n",
    "    points_ecef = np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    return np.array(points_ecef)\n",
    "\n",
    "input_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_utm.ply\"\n",
    "output_ply_path = \"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/SNU-35Back_workspace/50m/exports/pcd/filtered_ecef.ply\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "coords_utm = np.asarray(pcd.points)\n",
    "print(f\"Loaded {len(coords_utm)} points from {input_ply_path}\")\n",
    "\n",
    "# Convert ECEF to UTM\n",
    "transformer = utm_to_ecef_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_ecef = utm_to_ecef_points(coords_utm, transformer)\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(coords_ecef)\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3047504.68074928  4051184.25442885  3857815.59610601]\n",
      " [-3047507.34951665  4051186.55475769  3857811.00875926]\n",
      " [-3047511.06631932  4051183.40606937  3857811.55604814]\n",
      " [-3047508.20908455  4051180.82131159  3857816.5130461 ]]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "def utm_to_ecef_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for UTM to ECEF conversion.\"\"\"\n",
    "    return Transformer.from_crs(f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\", \"EPSG:4978\")\n",
    "\n",
    "def utm_to_ecef_points(points_utm: np.ndarray, transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts UTM points to ECEF coordinates.\n",
    "    \n",
    "    points_utm : (N, 3) - UTM coordinates (E, N, Altitude)\n",
    "    \"\"\"\n",
    "    \n",
    "    e, n, alt = points_utm[:, 0], points_utm[:, 1], points_utm[:, 2]\n",
    "    x, y, z = transformer.transform(e, n, alt)\n",
    "    points_ecef = np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    return np.array(points_ecef)\n",
    "\n",
    "coords_utm_y1 = np.array([    \n",
    "    [318890.442133, 4147487.223265, 140.161864],\n",
    "        [318890.909859, 4147481.202181, 140.201193],\n",
    "        [318895.667564, 4147481.597686, 140.240356], \n",
    "        [318895.201717, 4147487.595746, 140.205322],    \n",
    "    ], dtype=np.float64)\n",
    "\n",
    "coords_utm_j1 = np.array([    \n",
    "    [318890.849485, 4147481.063982, 140.179913],\n",
    "        [318891.481113, 4147475.233882, 140.122883],\n",
    "        [318896.339060, 4147475.711492, 140.231966], \n",
    "        [318895.749198, 4147481.881790, 140.243442],    \n",
    "    ], dtype=np.float64)\n",
    "\n",
    "transformer = utm_to_ecef_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_ecef_y1 = utm_to_ecef_points(coords_utm_y1, transformer)\n",
    "coords_ecef_j1 = utm_to_ecef_points(coords_utm_j1, transformer)\n",
    "print(coords_ecef_j1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[[ 318892.84107189 4147481.48802571]\n",
      " [ 318891.41463701 4147475.39550037]\n",
      " [ 318893.65244937 4147477.57361983]\n",
      " [ 318896.17264202 4147475.72848789]]\n",
      "\n",
      "[[ 318895.16213698 4147487.63786774]\n",
      " [ 318890.30214663 4147487.14235971]\n",
      " [ 318892.67867724 4147484.74360234]\n",
      " [ 318892.82241112 4147481.75383504]]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def ecef_to_utm_transformer(zone_number: int, zone_letter: str):\n",
    "    \"\"\"Creates a Transformer for ECEF to UTM conversion.\"\"\"\n",
    "    return Transformer.from_crs(\"EPSG:4978\", f\"+proj=utm +zone={zone_number} +{zone_letter} +datum=WGS84\")\n",
    "\n",
    "def ecef_to_utm_points(points_ecef: np.ndarray , transformer: Transformer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts ECEF points to UTM coordinates.\n",
    "    \n",
    "    points_ecef : (N, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, z = points_ecef[:, 0], points_ecef[:, 1], points_ecef[:, 2]\n",
    "    e, n, alt = transformer.transform(x, y, z)\n",
    "    points_utm = np.stack([e, n, alt], axis = -1) \n",
    "    \n",
    "    return np.array(points_utm)\n",
    "\n",
    "trans_cloudcompare = np.array([3047000.00, -4051000.00, -3857000.00], dtype = np.float64)\n",
    "\n",
    "\n",
    "coords_ecef_j1 = np.array(\n",
    "    [\n",
    "        [-506.078119, 182.807889, 816.023397],\n",
    "        [-507.263343, 186.535461, 811.139028],         \n",
    "        [-508.224556, 184.170274, 812.938215], # 소의 ㅗ\n",
    "        [-510.949760, 183.534916, 811.549471],\n",
    "        ]\n",
    ") \n",
    "\n",
    "coords_ecef_j1 -= trans_cloudcompare\n",
    "\n",
    "coords_ecef_y1 = np.array(\n",
    "        [[-505.581044, 178.509305, 820.971791],\n",
    "        [-501.903964, 181.685998, 820.466010],\n",
    "        [-504.697447, 181.360312, 818.597099],\n",
    "        [-505.958553, 182.689592, 816.230171]]\n",
    "    )    \n",
    "\n",
    "coords_ecef_y1 -= trans_cloudcompare\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "# Convert ECEF to UTM\n",
    "transformer = ecef_to_utm_transformer(zone_number=52, zone_letter=\"north\")\n",
    "coords_utm_j1 = ecef_to_utm_points(coords_ecef_j1, transformer)\n",
    "coords_utm_y1 = ecef_to_utm_points(coords_ecef_y1, transformer)\n",
    "print(coords_utm_j1[:, :2])\n",
    "print(\"\")\n",
    "print(coords_utm_y1[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 188 points from /workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/model_based_tracking.ply\n",
      "188\n",
      "Predicted points saved to /workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/GT.npy\n",
      "Predicted points saved to /workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/pred_points_uav.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Final evaluation(ATE)\n",
    "trans_cloudcompare = np.array([3047000.00, -4051000.00, -3857000.00], dtype = np.float64)\n",
    "GT_feature_vertices = np.array([\n",
    "        [-501.967988, 181.675080, 820.428803],\n",
    "        [-507.307352, 186.436744, 811.205693],\n",
    "        [-510.972234, 183.477112, 811.603174],\n",
    "        [-505.591991, 178.600039, 820.896150]\n",
    "    ])\n",
    "\n",
    "GT_feature_vertices -= trans_cloudcompare\n",
    "    \n",
    "    \n",
    "    \n",
    "# .ply 파일 읽기        \n",
    "input_ply_path = \"/workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/model_based_tracking.ply\"\n",
    "pcd = o3d.io.read_point_cloud(input_ply_path)\n",
    "print(f\"Loaded {len(pcd.points)} points from {input_ply_path}\")\n",
    "\n",
    "pred_points = np.asarray(pcd.points)  \n",
    "print(len(pred_points))\n",
    "\n",
    "\n",
    "GT_feature_vertices = ecef_to_utm_points(GT_feature_vertices, transformer)\n",
    "pred_points = ecef_to_utm_points(pred_points, transformer)\n",
    "\n",
    "GT_points_filename = \"/workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/GT.npy\"\n",
    "np.save(GT_points_filename, GT_feature_vertices)\n",
    "print(f\"Predicted points saved to {GT_points_filename}\")\n",
    "\n",
    "pred_points_filename = \"/workspace/Laboratory/00.CourseWork/24-2_ITAutocon/00.workspace/CCTV_result/pred_points_uav.npy\"\n",
    "np.save(pred_points_filename, pred_points)\n",
    "print(f\"Predicted points saved to {pred_points_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCD centering with translation.json\n",
    "\n",
    "import open3d as o3d\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. PCD 파일 불러오기\n",
    "pcd = o3d.io.read_point_cloud(\"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/pcd/filtered/filtered_ck.ply\")  # 'input.pcd'는 실제 파일 경로로 변경\n",
    "\n",
    "# 2. JSON 파일에서 translation 값 읽기\n",
    "with open(\"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/3dmesh/gps/translation_ck.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "translation_data = json_data[\"global_translation\"]\n",
    "\n",
    "# 3. x, y, z 추출\n",
    "\n",
    "\n",
    "# 4. 포인트 클라우드에 translation 적용\n",
    "translation_vector = - np.array(translation_data)\n",
    "pcd.translate(translation_vector)\n",
    "\n",
    "# 5. 결과 저장\n",
    "o3d.io.write_point_cloud(\"/workspace/Laboratory/02.Rapid3DReconstruction/00.workspace/Nakseongdae_50m_oblique_workspace/trial1/initial/nerf_output/exports/pcd/filtered/centered_filtered_ck.pcd\", pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
